{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# **DATA VISUALIZATION**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "1. Answer Business Requirement 1: Provide visual insights to differentiate between healthy and mildew-affected leaves.\n",
        "2. Visualize class distributions and image characteristics.\n",
        "3 Generate visuals to aid in building the Streamlit dashboard.\n",
        "\n",
        "## Inputs\n",
        "\n",
        "Dataset directories:\n",
        "- inputs/mildew_dataset/cherry-leaves/train\n",
        "- inputs/mildew_dataset/cherry-leaves/validation\n",
        "- inputs/mildew_dataset/cherry-leaves/test\n",
        "\n",
        "## Outputs\n",
        "\n",
        "- Image shape embeddings pickle file.\n",
        "- Mean and variability of images per label plot.\n",
        "- Visualization of class distributions.\n",
        "- Image montage for use in the Streamlit dashboard.\n",
        "\n",
        "## Additional Comments\n",
        "\n",
        "- Data visualization provides insights into dataset quality, balance, and structure.\n",
        "- Helps in identifying potential biases or imbalances in the dataset.\n",
        "- Supports informed decisions regarding preprocessing, data augmentation, and modeling strategies.\n",
        "- Ensures that the dataset is well-prepared for the modeling phase by revealing class imbalances and image variability.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqP-UeN-z3i2"
      },
      "source": [
        "# Set Up Environment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import joblib\n",
        "sns.set_style(\"white\")\n",
        "from matplotlib.image import imread"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Set Working Directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZfF_j-Bz3i4",
        "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
      },
      "outputs": [],
      "source": [
        "cwd= os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TwHsQRWjz3i9",
        "outputId": "86849db3-cd2f-4cc5-ebb8-2d0caafa1a2c"
      },
      "outputs": [],
      "source": [
        "os.chdir('/workspace/mildew-detection-app')\n",
        "print(\"You set a new current directory\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vz3S-_kjz3jA",
        "outputId": "00b79ae4-75d0-4a96-d193-ac9ef9847ea2"
      },
      "outputs": [],
      "source": [
        "work_dir = os.getcwd()\n",
        "work_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mavJ8DibrcQ"
      },
      "source": [
        "### Set Input Directories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set input directories\n",
        "my_data_dir = 'inputs/mildew_dataset/cherry-leaves'\n",
        "train_path = os.path.join(my_data_dir, 'train')\n",
        "val_path = os.path.join(my_data_dir, 'validation')\n",
        "test_path = os.path.join(my_data_dir, 'test')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFQo3ycuO-v6"
      },
      "source": [
        "### Set Output Directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "version = 'v1'\n",
        "file_path = f'outputs/{version}'\n",
        "\n",
        "if 'outputs' in os.listdir(work_dir) and version in os.listdir(work_dir + '/outputs'):\n",
        "    print('Old version is already available create a new version.')\n",
        "    pass\n",
        "else:\n",
        "    os.makedirs(name=file_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Set Label Names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set the labels for the images\n",
        "labels = os.listdir(train_path)\n",
        "print('Label for the images are', labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Visualization of Image Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Image Shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compute average image dimensions on the train set\n",
        "dim1, dim2 = [], []\n",
        "for label in labels:\n",
        "    for image_filename in os.listdir(train_path + '/' + label):\n",
        "        img = imread(train_path + '/' + label + '/' + image_filename)\n",
        "        d1, d2, colors = img.shape\n",
        "        dim1.append(d1)  # image height\n",
        "        dim2.append(d2)  # image width\n",
        "\n",
        "# Plot image dimensions\n",
        "sns.set_style(\"whitegrid\")\n",
        "fig, axes = plt.subplots()\n",
        "sns.scatterplot(x=dim2, y=dim1, alpha=0.2)\n",
        "axes.set_xlabel(\"Width (pixels)\")\n",
        "axes.set_ylabel(\"Height (pixels)\")\n",
        "dim1_mean = int(np.array(dim1).mean())\n",
        "dim2_mean = int(np.array(dim2).mean())\n",
        "axes.axvline(x=dim1_mean, color='r', linestyle='--')\n",
        "axes.axhline(y=dim2_mean, color='r', linestyle='--')\n",
        "plt.show()\n",
        "print(f\"Width average: {dim2_mean} \\nHeight average: {dim1_mean}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Image size is set to 128×128 to reduce computational cost and overfitting risk while preserving essential features for classification."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "image_shape = (128, 128, 3)\n",
        "image_shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Save the Image Shape Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "joblib.dump(value=image_shape ,\n",
        "            filename=f\"{file_path}/image_shape.pkl\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Image Statistics (Mean & Variability)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Function to Load Images into Arrays"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "def load_image_as_array(my_data_dir, new_size=image_shape[:2], n_images_per_label=20):\n",
        "    \"\"\"\n",
        "    Loads images, resizes them, and returns them as arrays with labels.\n",
        "    \"\"\"\n",
        "    X, y = np.array([], dtype='int'), np.array([], dtype='object')\n",
        "    labels = os.listdir(my_data_dir)\n",
        "\n",
        "    for label in labels:\n",
        "        counter = 0\n",
        "        for image_filename in os.listdir(my_data_dir + '/' + label):\n",
        "            if counter < n_images_per_label:\n",
        "                img = image.load_img(\n",
        "                    my_data_dir + '/' + label + '/' + image_filename, \n",
        "                    target_size=new_size)  # (height, width)\n",
        "\n",
        "                img_resized = image.img_to_array(img) / 255  # Normalize pixel values\n",
        "\n",
        "                # Append image data and reshape correctly\n",
        "                X = np.append(X, img_resized).reshape(-1, new_size[0], new_size[1], img_resized.shape[2])\n",
        "                y = np.append(y, label)\n",
        "                counter += 1\n",
        "\n",
        "    return X, y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Load Image Shapes and Labels in an Array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X, y = load_image_as_array(my_data_dir=train_path,\n",
        "                           new_size=image_shape,\n",
        "                           n_images_per_label=30)\n",
        "print(X.shape, y.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Plot Mean and Variability"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_mean_variability_per_labels(X, y, figsize=(12, 5), save_image=False):\n",
        "    \"\"\"\n",
        "    The pseudo-code for the function is:\n",
        "    * Iterate through all unique labels in the dataset.\n",
        "    * Filter the dataset to include only images corresponding to the current label.\n",
        "    * Calculate the mean and standard deviation for the filtered subset.\n",
        "    * Create a figure with two subplots:\n",
        "        - One displaying the mean image for the label.\n",
        "        - The other showing the variability (standard deviation) image.\n",
        "    * Optionally save the generated plots to the specified directory.\n",
        "    \"\"\"\n",
        "\n",
        "    for label_to_display in np.unique(y):\n",
        "        sns.set_style(\"white\")  # Set the plot style\n",
        "\n",
        "        # Create a boolean mask to filter images for the current label\n",
        "        boolean_mask = (y == label_to_display)\n",
        "        arr = X[boolean_mask]\n",
        "\n",
        "        # Compute the mean image and standard deviation image for the current label\n",
        "        avg_img = np.mean(arr, axis=0)\n",
        "        std_img = np.std(arr, axis=0)\n",
        "\n",
        "        print(f\"==== Label {label_to_display} ====\")\n",
        "        print(f\"Image Shape: {avg_img.shape}\")\n",
        "\n",
        "        # Create a figure to display the average and variability images\n",
        "        fig, axes = plt.subplots(nrows=1, ncols=2, figsize=figsize)\n",
        "        axes[0].set_title(f\"Average image for label {label_to_display}\")\n",
        "        if avg_img.shape[-1] == 3:  # Check if RGB\n",
        "            axes[0].imshow(avg_img)  # No cmap for RGB\n",
        "            axes[1].imshow(std_img)\n",
        "        else:  # Grayscale\n",
        "            axes[0].imshow(avg_img, cmap='gray')\n",
        "            axes[1].imshow(std_img, cmap='gray')\n",
        "\n",
        "        axes[1].set_title(f\"Variability image for label {label_to_display}\")\n",
        "\n",
        "        # Save or display the figure based on the `save_image` argument\n",
        "        if save_image:\n",
        "            plt.savefig(f\"{file_path}/avg_var_{label_to_display}.png\",\n",
        "                        bbox_inches='tight', dpi=150)\n",
        "        else:\n",
        "            plt.tight_layout()  # Adjust layout for better spacing\n",
        "            plt.show()\n",
        "        print(\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_mean_variability_per_labels(X=X, y=y, figsize=(12, 5), save_image=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Counts image files within a directory structure, handling missing directories and providing a total count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "sets = ['train', 'test', 'validation']\n",
        "labels = ['Healthy', 'Infected']  \n",
        "\n",
        "for set_name in sets:\n",
        "    for label in labels:\n",
        "        path = f'inputs/mildew_dataset/cherry-leaves/{set_name}/{label}' \n",
        "        try:\n",
        "            number_of_files = len(os.listdir(path))\n",
        "            print(f'There are {number_of_files} images in {set_name}/{label}')\n",
        "        except FileNotFoundError:\n",
        "            print(f\"Error: Directory '{path}' not found.\")\n",
        "\n",
        "# Calculate and print total number of images\n",
        "total_images = 0\n",
        "for set_name in sets:\n",
        "    for label in labels:\n",
        "        path = f'inputs/mildew_dataset/cherry-leaves/{set_name}/{label}'  \n",
        "        try:\n",
        "            total_images += len(os.listdir(path))\n",
        "        except FileNotFoundError:\n",
        "            pass\n",
        "print(f\"\\nTotal number of images: {total_images}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Dataset Distribution & Image Characteristics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Bar Chart of Image Distribution & Pie Chart of Overall Label Distribution: visualizing the number of images in train, validation, and the test per label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Initialize dictionary to store dataset statistics\n",
        "data = {\n",
        "    'Set': [],\n",
        "    'Label': [],\n",
        "    'Frequency': []\n",
        "}\n",
        "\n",
        "# Define dataset folders: train, validation, and test\n",
        "folders = ['train', 'validation', 'test']\n",
        "\n",
        "# Iterate through dataset folders and count images per label\n",
        "for folder in folders:\n",
        "    for label in labels:\n",
        "        row = {\n",
        "            'Set': folder,\n",
        "            'Label': label,\n",
        "            'Frequency': int(len(os.listdir(os.path.join(my_data_dir, folder, label))))\n",
        "        }\n",
        "        for key, value in row.items():\n",
        "            data[key].append(value)\n",
        "\n",
        "# Convert the dictionary into a DataFrame\n",
        "df_freq = pd.DataFrame(data)\n",
        "\n",
        "# **Bar Chart of Image Distribution**\n",
        "sns.set_style(\"whitegrid\")\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.barplot(data=df_freq, x='Set', y='Frequency', hue='Label')\n",
        "plt.title(\"Image Distribution in Dataset\")\n",
        "plt.savefig(f'{file_path}/labels_distribution.png', bbox_inches='tight', dpi=150)\n",
        "plt.show()\n",
        "\n",
        "# **Pie Chart of Overall Label Distribution**\n",
        "plt.figure(figsize=(6, 6))\n",
        "label_distribution = df_freq.groupby(\"Label\")[\"Frequency\"].sum()\n",
        "\n",
        "plt.pie(label_distribution, labels=label_distribution.index, autopct='%1.1f%%', colors=[\"#1f77b4\", \"#ff7f0e\"], startangle=90)\n",
        "plt.title(\"Overall Class Distribution (Healthy vs Infected)\")\n",
        "plt.savefig(f'{file_path}/labels_pie_chart.png', bbox_inches='tight', dpi=150)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Comparing Healthy vs. Infected Leaves"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def subset_image_label(X, y, label_to_display):\n",
        "    \"\"\"\n",
        "    Filters the dataset to include only the images that belong to a specific label.\n",
        "    \"\"\"\n",
        "    # Create a boolean mask to filter for the given label\n",
        "    boolean_mask = (y == label_to_display)\n",
        "    df = X[boolean_mask]  # Subset the dataset\n",
        "    return df\n",
        "\n",
        "\n",
        "def diff_bet_avg_image_labels_data_as_array(X, y, label_1, label_2, figsize=(20, 5), save_image=False):\n",
        "    \"\"\"\n",
        "    Compares the average images between two specified labels.\n",
        "\n",
        "    - Verifies that both labels exist in the dataset.\n",
        "    - Calculates the mean image for each label.\n",
        "    - Calculate pixel-wise difference between class averages\n",
        "    - Displays or optionally saves a figure with:\n",
        "        * Average image for label_1\n",
        "        * Average image for label_2\n",
        "        * Difference between the two averages\n",
        "    \"\"\"\n",
        "    sns.set_style(\"white\")\n",
        "\n",
        "    # Validate that both labels are present in the dataset\n",
        "    unique_labels = np.unique(y)\n",
        "    if (label_1 not in unique_labels) or (label_2 not in unique_labels):\n",
        "        print(f\"Either label {label_1} or label {label_2} is not in {unique_labels}\")\n",
        "        return\n",
        "\n",
        "    # Calculate mean from label_1\n",
        "    images_label = subset_image_label(X, y, label_1)\n",
        "    label1_avg = np.mean(images_label, axis=0)\n",
        "\n",
        "    # Calculate mean from label_2\n",
        "    images_label = subset_image_label(X, y, label_2)\n",
        "    label2_avg = np.mean(images_label, axis=0)\n",
        "\n",
        "    # Calculate pixel-wise difference between class averages\n",
        "    difference_mean = label1_avg - label2_avg\n",
        "\n",
        "    # Create and display a plot with the results\n",
        "    fig, axes = plt.subplots(nrows=1, ncols=3, figsize=figsize)\n",
        "    \n",
        "    # Determine if the images are RGB or Grayscale\n",
        "    is_rgb = label1_avg.shape[-1] == 3\n",
        "\n",
        "    axes[0].imshow(label1_avg if is_rgb else label1_avg, cmap=None if is_rgb else 'gray')\n",
        "    axes[0].set_title(f'Average {label_1}')\n",
        "\n",
        "    axes[1].imshow(label2_avg if is_rgb else label2_avg, cmap=None if is_rgb else 'gray')\n",
        "    axes[1].set_title(f'Average {label_2}')\n",
        "\n",
        "    axes[2].imshow(difference_mean if is_rgb else difference_mean, cmap=None if is_rgb else 'gray')\n",
        "    axes[2].set_title(f'Difference image: Avg {label_1} & {label_2}')\n",
        "\n",
        "    # Save the plot to a file if save_image=True, otherwise display it\n",
        "    if save_image:\n",
        "        plt.savefig(f\"{file_path}/avg_diff.png\", bbox_inches='tight', dpi=150)\n",
        "    else:\n",
        "        plt.tight_layout()\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "diff_bet_avg_image_labels_data_as_array(X=X, y=y,\n",
        "                                        label_1='Healthy', label_2='Infected',\n",
        "                                        figsize=(12, 10),\n",
        "                                        save_image=True\n",
        "                                        )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Image Montage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import itertools\n",
        "import random\n",
        "sns.set_style(\"white\")\n",
        "\n",
        "\n",
        "def image_montage(dir_path, label_to_display, nrows, ncols, figsize=(15, 10)):\n",
        "    \"\"\"\n",
        "    - Verify if the specified label exists in the directory.\n",
        "    - Ensure the grid size (nrows * ncols) does not exceed the number of available images.\n",
        "    - Select random images to fill the montage grid\n",
        "    - Create a figure to display the images, loading and plotting each in the respective grid space.\n",
        "    \"\"\"\n",
        "\n",
        "    labels = os.listdir(dir_path)\n",
        "\n",
        "    # Check if the specified label exists in the directory\n",
        "    if label_to_display in labels:\n",
        "\n",
        "        # Validate that the montage grid can fit the available images\n",
        "        images_list = os.listdir(dir_path + '/' + label_to_display)\n",
        "        if nrows * ncols <= len(images_list):  \n",
        "            img_idx = random.sample(images_list, nrows * ncols)\n",
        "        else:\n",
        "            print(\n",
        "                f\"Reduce the number of rows or columns for the montage. \\n\"\n",
        "                f\"There are only {len(images_list)} images available. \"\n",
        "                f\"You requested a grid for {nrows * ncols} images.\")\n",
        "            return\n",
        "\n",
        "        # Generate grid indices based on the number of rows and columns\n",
        "        list_rows = range(0, nrows)\n",
        "        list_cols = range(0, ncols)\n",
        "        plot_idx = list(itertools.product(list_rows, list_cols))\n",
        "\n",
        "        # Create a figure and populate it with the selected images\n",
        "        fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=figsize)\n",
        "        for x in range(0, nrows * ncols):\n",
        "            img = imread(dir_path + '/' + label_to_display + '/' + img_idx[x])\n",
        "            img_shape = img.shape\n",
        "            axes[plot_idx[x][0], plot_idx[x][1]].imshow(img)\n",
        "            axes[plot_idx[x][0], plot_idx[x][1]].set_title(\n",
        "                f\"Width: {img_shape[1]}px, Height: {img_shape[0]}px\")\n",
        "            axes[plot_idx[x][0], plot_idx[x][1]].set_xticks([])\n",
        "            axes[plot_idx[x][0], plot_idx[x][1]].set_yticks([])\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "        plt.close(fig)  \n",
        "\n",
        "    else:\n",
        "        # Notify the user if the selected label does not exist\n",
        "        print(f\"The selected label '{label_to_display}' does not exist.\")\n",
        "        print(f\"Available labels are: {labels}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Run Montage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for label in labels:\n",
        "    print(label)\n",
        "    image_montage(dir_path=train_path,\n",
        "                  label_to_display=label,\n",
        "                  nrows=3, ncols=3,\n",
        "                  figsize=(10, 15)\n",
        "                  )\n",
        "    print(\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Statistical Testing on Image Characteristics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Statistical Testing (t-test on image brightness): quantitatively compares Healthy vs. Infected leaves to support the business requirement of differentiating between them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from scipy.stats import ttest_ind\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
        "\n",
        "# Paths to image data\n",
        "test_healthy_dir = os.path.join(test_path, \"Healthy\")\n",
        "test_infected_dir = os.path.join(test_path, \"Infected\")\n",
        "\n",
        "# List of images (50 from each class)\n",
        "healthy_images = [os.path.join(test_healthy_dir, img) for img in os.listdir(test_healthy_dir)[:50]]\n",
        "infected_images = [os.path.join(test_infected_dir, img) for img in os.listdir(test_infected_dir)[:50]]\n",
        "\n",
        "def preprocess_grayscale(image_path, target_size=(128, 128)):\n",
        "    img = load_img(image_path, target_size=target_size, color_mode=\"grayscale\")\n",
        "    img_array = img_to_array(img) / 255.0  # Normalize\n",
        "    return img_array.flatten()  \n",
        "\n",
        "healthy_data = np.array([preprocess_grayscale(img) for img in healthy_images])\n",
        "infected_data = np.array([preprocess_grayscale(img) for img in infected_images])\n",
        "\n",
        "# Perform t-test\n",
        "t_stat, p_value = ttest_ind(healthy_data.flatten(), infected_data.flatten())\n",
        "\n",
        "# Display results\n",
        "print(f\"t-statistic: {t_stat:.4f}\")\n",
        "print(f\"p-value: {p_value:.4e}\")\n",
        "\n",
        "if p_value < 0.05:\n",
        "    print(\"There is a significant difference in pixel intensity distributions.\")\n",
        "else:\n",
        "    print(\"No statistically significant difference between classes.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Feature Differences"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### PCA Visualization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This helps in visualizing differences in feature space, which aligns with your objective of highlighting visual differences."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.decomposition import PCA\n",
        "import seaborn as sns\n",
        "\n",
        "# Convert to NumPy array\n",
        "X_flat = X.reshape(len(X), -1)  # Flatten images for PCA\n",
        "\n",
        "# Apply PCA (reduce to 2 dimensions)\n",
        "pca = PCA(n_components=2)\n",
        "X_pca = pca.fit_transform(X_flat)\n",
        "\n",
        "# Visualize results\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.scatterplot(x=X_pca[:, 0], y=X_pca[:, 1], hue=y, palette={\"Healthy\": \"blue\", \"Infected\": \"red\"}, alpha=0.7)\n",
        "plt.xlabel(\"Principal Component 1\")\n",
        "plt.ylabel(\"Principal Component 2\")\n",
        "plt.title(\"PCA Visualization of Leaf Images\")\n",
        "plt.legend(title=\"Class\")\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### t-SNE Visualization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This helps understand separability in feature space, useful for analyzing visual clusters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.manifold import TSNE\n",
        "\n",
        "# Apply t-SNE (reduce to 2 dimensions)\n",
        "tsne = TSNE(n_components=2, perplexity=30, random_state=42)\n",
        "X_tsne = tsne.fit_transform(X_flat)\n",
        "\n",
        "# Visualize results\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.scatterplot(x=X_tsne[:, 0], y=X_tsne[:, 1], hue=y, palette={\"Healthy\": \"blue\", \"Infected\": \"red\"}, alpha=0.7)\n",
        "plt.xlabel(\"t-SNE Component 1\")\n",
        "plt.ylabel(\"t-SNE Component 2\")\n",
        "plt.title(\"t-SNE Visualization of Leaf Images\")\n",
        "plt.legend(title=\"Class\")\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Histogram of Pixel Intensity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This shows how color intensities vary between the two classes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create Histogram\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.hist(healthy_data.flatten(), bins=30, alpha=0.7, label=\"Healthy\", color=\"blue\", density=True)\n",
        "plt.hist(infected_data.flatten(), bins=30, alpha=0.7, label=\"Infected\", color=\"red\", density=True)\n",
        "plt.xlabel(\"Pixel Intensity\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.legend()\n",
        "plt.title(\"Histogram of Pixel Intensity (Healthy vs Infected)\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Image Explainability & Feature Importance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Grad-CAM Heatmap for Explainability"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This shows which parts of an image contribute most to classification."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "import cv2\n",
        "\n",
        "def get_grad_cam(model, img_array, layer_name):\n",
        "    grad_model = Model(inputs=model.input, outputs=[model.get_layer(layer_name).output, model.output])\n",
        "    with tf.GradientTape() as tape:\n",
        "        conv_outputs, predictions = grad_model(img_array)\n",
        "        loss = predictions[:, 0]\n",
        "    grads = tape.gradient(loss, conv_outputs)\n",
        "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
        "    heatmap = tf.reduce_sum(tf.multiply(pooled_grads, conv_outputs), axis=-1)\n",
        "    heatmap = np.maximum(heatmap, 0) / np.max(heatmap)\n",
        "    return heatmap[0]\n",
        "\n",
        "# Apply to a sample image\n",
        "grad_cam_map = get_grad_cam(model, np.expand_dims(X[0], axis=0), 'conv2d_2')\n",
        "\n",
        "# Overlay heatmap on original image\n",
        "heatmap = cv2.resize(grad_cam_map, (128, 128))\n",
        "heatmap = cv2.applyColorMap(np.uint8(255 * heatmap), cv2.COLORMAP_JET)\n",
        "superimposed_img = cv2.addWeighted(X[0], 0.5, heatmap, 0.5, 0)\n",
        "\n",
        "plt.imshow(superimposed_img)\n",
        "plt.title(\"Grad-CAM Visualization\")\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Occlusion Sensitivity Map"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This helps understand how image regions impact classification."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def occlusion_sensitivity(model, img_array, patch_size=20, stride=10):\n",
        "    img_height, img_width, _ = img_array.shape[1:]\n",
        "    orig_pred = model.predict(img_array)[0, 0]  \n",
        "    sensitivity_map = np.zeros((img_height, img_width))\n",
        "\n",
        "    for y in range(0, img_height, stride):\n",
        "        for x in range(0, img_width, stride):\n",
        "            occluded_img = img_array.copy()\n",
        "            occluded_img[:, y:y+patch_size, x:x+patch_size, :] = 0  \n",
        "\n",
        "            new_pred = model.predict(occluded_img)[0, 0]\n",
        "            sensitivity_map[y:y+patch_size, x:x+patch_size] = abs(orig_pred - new_pred)\n",
        "\n",
        "    return sensitivity_map\n",
        "\n",
        "# Generate occlusion map\n",
        "sensitivity_map = occlusion_sensitivity(model, np.expand_dims(X[0], axis=0))\n",
        "\n",
        "# Plot occlusion sensitivity map\n",
        "plt.figure(figsize=(6, 6))\n",
        "plt.imshow(sensitivity_map, cmap=\"hot\")\n",
        "plt.colorbar()\n",
        "plt.title(\"Occlusion Sensitivity Map\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conclusion and Next Steps\n",
        "\n",
        "### Summary of Findings\n",
        "This notebook provided **a comprehensive visual analysis** of the cherry leaf dataset. Key takeaways include:\n",
        "\n",
        "- Image Dimensions: Most images are approximately 128×128 pixels, ensuring standardization.\n",
        "- Class Distribution: The dataset appears balanced between healthy and infected leaves.\n",
        "- Mean & Variability Analysis:\n",
        "- Healthy leaves show consistent structure.\n",
        "- Infected leaves exhibit higher variability, likely due to different infection stages.\n",
        "- Image Montage: Representative samples confirm dataset quality and balance.\n",
        "\n",
        "### Next Steps\n",
        "1. Integrate Visuals into the Streamlit Dashboard\n",
        "- Use image montages for interactive dataset exploration.\n",
        "- Display class distributions and image variability.\n",
        "\n",
        "2. Enhance Data Preprocessing\n",
        "- Apply data augmentation based on observed variability.\n",
        "- Consider histogram equalization to improve contrast.\n",
        "\n",
        "3. Model Training & Feature Engineering\n",
        "- Utilize the image shape information for preprocessing.\n",
        "- Experiment with feature extraction (e.g., PCA, edge detection).\n",
        "\n",
        "4. Further Improvements\n",
        "- Analyze color distribution differences between classes (e.g., HSV transformation).\n",
        "- Expand visualizations to include pixel intensity distributions.\n",
        "\n",
        "This concludes the Data Visualization phase. The next step is to prepare the dataset for model training and implement necessary preprocessing techniques."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "interpreter": {
      "hash": "8b8334dab9339717f727a1deaf837b322d7a41c20d15cc86be99a8e69ceec8ce"
    },
    "kernelspec": {
      "display_name": "Python 3.8.12 64-bit ('3.8.12': pyenv)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
