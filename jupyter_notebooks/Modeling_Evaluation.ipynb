{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# **MODELING and EVALUATION**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Business Requirement**\n",
        "- Address **Business Requirement 2**: Develop a classification model to detect **powdery mildew** on cherry leaves.\n",
        "- Automate disease detection to **save time** and **improve efficiency** in plantation management.\n",
        "- Compare different **machine learning models** to determine the **most efficient and accurate** solution.\n",
        "\n",
        "---\n",
        "\n",
        "## **Objectives**\n",
        "1. **Baseline CNN Model**: Implement a **simplified CNN** to establish a reference point.\n",
        "2. **Transfer Learning with MobileNetV2**: Use **pre-trained MobileNetV2** to leverage feature extraction from ImageNet.\n",
        "3. **Optimized Hyperparameter Tuning**: Perform a **lightweight** tuning process to improve performance **without high computation costs**.\n",
        "4. **Model Evaluation & Explainability**:  \n",
        "   - Compare **CNN vs. MobileNetV2** performance (baseline & tuned).  \n",
        "   - Visualize **model focus areas** using **Grad-CAM**.  \n",
        "5. **Final Model Selection**: Choose the best model for **deployment** based on **accuracy, efficiency, and business requirements**.\n",
        "\n",
        "---\n",
        "\n",
        "## **Inputs**\n",
        "### **Dataset**\n",
        "- **Train Data** → `inputs/mildew_dataset/cherry-leaves/train`\n",
        "- **Validation Data** → `inputs/mildew_dataset/cherry-leaves/validation`\n",
        "- **Test Data** → `inputs/mildew_dataset/cherry-leaves/test`\n",
        "\n",
        "### **Precomputed Features (from Data Visualization Notebook)**\n",
        "- **Image Shape Standardization** → **128x128x3** for consistency across models.\n",
        "- **Class Distribution Analysis** → Ensures balanced dataset splits.\n",
        "- **Feature Space Visualization** → **PCA confirms class separability**.\n",
        "- **Pixel Intensity Distribution** → Confirms brightness variations relevant for classification.\n",
        "\n",
        "---\n",
        "\n",
        "## **Outputs**\n",
        "### **Data Processing & Visualization**\n",
        "- **Dataset Distribution Plot** → Confirms class balance across training, validation, and test sets.\n",
        "- **Data Augmentation Visualization** → Shows the impact of transformations applied to training data.\n",
        "\n",
        "### **Model Training & Optimization**\n",
        "1. **Simplified CNN Model** → Establishes baseline performance.\n",
        "2. **MobileNetV2 Transfer Learning** → Leverages pre-trained knowledge for improved classification.\n",
        "3. **Hyperparameter Tuning** → Fine-tunes **learning rate, dropout, and L2 regularization** while keeping computation light.\n",
        "4. **Best Model Selection** → Based on **test accuracy and generalization ability**.\n",
        "5. **Saved Trained Models** → Ready for **Streamlit integration** and **deployment**.\n",
        "\n",
        "### **Model Evaluation & Explainability**\n",
        "- **Training Progress Visualization** → Learning curves for loss & accuracy trends.\n",
        "- **Confusion Matrix** → Static visualizations for **train, validation, and test sets**.\n",
        "- **Classification Report** → Detailed **precision, recall, and F1-score** breakdown.\n",
        "- **Grad-CAM Heatmap** → Highlights **which areas of the image** were most important in classification.\n",
        "\n",
        "### **Final Model Selection**\n",
        "- **Compare CNN vs. MobileNetV2 (Base & Tuned)**\n",
        "- **Choose the best model based on performance, efficiency, and deployment feasibility**\n",
        "- **Deploy the final model for real-world use in a Streamlit application**\n",
        "\n",
        "---\n",
        "\n",
        "## **Additional Comments**\n",
        "- **Business Impact**: A reliable model reduces **manual inspection time** and improves **plantation monitoring efficiency**.\n",
        "- **Data-Driven Enhancements**: Model optimizations are based on **insights from data preprocessing and visualization**.\n",
        "- **Deployment-Ready**: The best-performing model is **optimized for integration into a Streamlit web app**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Setup & Data Preparation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqP-UeN-z3i2"
      },
      "source": [
        "### **Import Necessary Packages**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from matplotlib.image import imread"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Set Working Directory & File Paths**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cwd= os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "os.chdir('/workspaces/mildew-detection-app')\n",
        "print(\"You set a new current directory\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZfF_j-Bz3i4",
        "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
      },
      "outputs": [],
      "source": [
        "work_dir = os.getcwd()\n",
        "work_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mavJ8DibrcQ"
      },
      "source": [
        "**Set Input Directories**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set train, validation and test paths\n",
        "my_data_dir = 'inputs/mildew_dataset/cherry-leaves'\n",
        "train_path = my_data_dir + '/train'\n",
        "val_path = my_data_dir + '/validation'\n",
        "test_path = my_data_dir + '/test'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Set Output Directory**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "version = 'v1'\n",
        "file_path = f'outputs/{version}'\n",
        "\n",
        "if 'outputs' in os.listdir(work_dir) and version in os.listdir(work_dir + '/outputs'):\n",
        "    print('Old version is already available create a new version.')\n",
        "    pass\n",
        "else:\n",
        "    os.makedirs(name=file_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Load Dataset & Labels**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Set Labels**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set the lables for the images\n",
        "labels = os.listdir(train_path)\n",
        "\n",
        "print(\n",
        "    f\"Project Labels: {labels}\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Load Precomputed Image Shape from Data Visualization Notebook**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Import saved image shape embedding\n",
        "import joblib\n",
        "version = 'v1'\n",
        "image_shape = joblib.load(filename=f\"outputs/{version}/image_shape.pkl\")\n",
        "image_shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Count and Visualize Dataset Distribution**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Count Images in Each Dataset Split**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create an empty dictionary\n",
        "data = {\n",
        "    'Set': [],\n",
        "    'Label': [],\n",
        "    'Frequency': []\n",
        "}\n",
        "\n",
        "# Define dataset folders\n",
        "folders = ['train', 'validation', 'test']\n",
        "\n",
        "# Loop through each dataset split and count images\n",
        "for folder in folders:\n",
        "    for label in labels:\n",
        "        path = os.path.join(my_data_dir, folder, label)\n",
        "        num_images = len(os.listdir(path)) if os.path.exists(path) else 0  # Handle missing directories\n",
        "        data['Set'].append(folder)\n",
        "        data['Label'].append(label)\n",
        "        data['Frequency'].append(num_images)\n",
        "        print(f\" {folder}/{label}: {num_images} images\")\n",
        "\n",
        "# Convert dictionary to DataFrame\n",
        "df_freq = pd.DataFrame(data)\n",
        "\n",
        "# ** Bar Chart - Image Distribution**\n",
        "print(f\"Bar Chart: Image distribution across dataset splits.\")\n",
        "sns.set_style(\"whitegrid\")\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.barplot(data=df_freq, x='Set', y='Frequency', hue='Label')\n",
        "plt.title(\"Image Distribution in Dataset\")\n",
        "plt.xlabel(\"Dataset Split\")\n",
        "plt.ylabel(\"Number of Images\")\n",
        "plt.savefig(f'{file_path}/labels_distribution.png', bbox_inches='tight', dpi=150)\n",
        "plt.show()\n",
        "\n",
        "# ** Pie Chart - Class Distribution**\n",
        "print(f\"Pie Chart: Overall class distribution (Healthy vs Infected).\")\n",
        "plt.figure(figsize=(5, 5))\n",
        "label_distribution = df_freq.groupby(\"Label\")[\"Frequency\"].sum()\n",
        "plt.pie(label_distribution, labels=label_distribution.index, autopct='%1.1f%%', startangle=90, colors=[\"#1f77b4\", \"#ff7f0e\"])\n",
        "plt.title(\"Overall Class Distribution (Healthy vs Infected)\")\n",
        "plt.savefig(f'{file_path}/labels_pie_chart.png', bbox_inches='tight', dpi=150)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY3l0-AxO93d"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Implement Data Augmentation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Define Augmentation Techniques**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Rotation, width/height shift, zoom, shear, horizontal/vertical flip, rescaling."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import TensorFlow/Keras ImageDataGenerator\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Augment Training, Validation, and Test Sets**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFQo3ycuO-v6"
      },
      "source": [
        "**Initialize ImageDataGenerator for Data Augmentation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define Augmentation for Training Set\n",
        "augmented_image_data = ImageDataGenerator(rotation_range=20,\n",
        "                                          width_shift_range=0.10,\n",
        "                                          height_shift_range=0.10,\n",
        "                                          shear_range=0.1,\n",
        "                                          zoom_range=0.1,\n",
        "                                          horizontal_flip=True,\n",
        "                                          vertical_flip=True,\n",
        "                                          fill_mode='nearest',\n",
        "                                          rescale=1./255\n",
        "                                          )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Augment Training Image Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "batch_size = 20  # Set batch size\n",
        "train_set = augmented_image_data.flow_from_directory(train_path,\n",
        "                                                     target_size=image_shape[:2],\n",
        "                                                     color_mode='rgb',\n",
        "                                                     batch_size=batch_size,\n",
        "                                                     class_mode='binary',\n",
        "                                                     shuffle=True\n",
        "                                                     )\n",
        "\n",
        "train_set.class_indices"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Augment Validation Image Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "validation_set = ImageDataGenerator(rescale=1./255).flow_from_directory(val_path,\n",
        "                                                                        target_size=image_shape[:2],\n",
        "                                                                        color_mode='rgb',\n",
        "                                                                        batch_size=batch_size,\n",
        "                                                                        class_mode='binary',\n",
        "                                                                        shuffle=False\n",
        "                                                                        )\n",
        "\n",
        "validation_set.class_indices"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Augment Test Image Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_set = ImageDataGenerator(rescale=1./255).flow_from_directory(test_path,\n",
        "                                                                  target_size=image_shape[:2],\n",
        "                                                                  color_mode='rgb',\n",
        "                                                                  batch_size=batch_size,\n",
        "                                                                  class_mode='binary',\n",
        "                                                                  shuffle=False\n",
        "                                                                  )\n",
        "\n",
        "test_set.class_indices"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Visualization of Augmented Images**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Plot Augmented Training Image**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for _ in range(3):\n",
        "    img, label = next(train_set)\n",
        "    print(img.shape)  # (1,256,256,3)\n",
        "    plt.imshow(img[0])\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Plot Augmented Validation and Test Images**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for _ in range(3):\n",
        "    img, label = next(validation_set)\n",
        "    print(img.shape)  # (1,256,256,3)\n",
        "    plt.imshow(img[0])\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for _ in range(3):\n",
        "    img, label = next(test_set)\n",
        "    print(img.shape)  # (1,256,256,3)\n",
        "    plt.imshow(img[0])\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Save Class Indices**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "joblib.dump(value=train_set.class_indices,\n",
        "            filename=f\"{file_path}/class_indices.pkl\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Compare Multiple Augmented Images in a Grid**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_augmented_images_grid(data_generator, num_images=10):\n",
        "    \"\"\"Displays a grid of augmented images to visualize transformation effects.\"\"\"\n",
        "    img_batch, label_batch = next(data_generator)\n",
        "\n",
        "    fig, axes = plt.subplots(2, num_images // 2, figsize=(15, 6))\n",
        "    \n",
        "    for i in range(num_images):\n",
        "        ax = axes[i // (num_images // 2), i % (num_images // 2)]\n",
        "        ax.imshow(img_batch[i])\n",
        "        ax.axis(\"off\")\n",
        "\n",
        "    plt.suptitle(\"Augmented Image Variations (Training Set)\")\n",
        "    plt.show()\n",
        "\n",
        "# Display the augmented image grid\n",
        "plot_augmented_images_grid(train_set)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Model Creation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Import Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Base Convolutional Neural Network (CNN)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This **lightweight CNN** is designed as a baseline to classify cherry leaves as **Healthy** or **Infected with Powdery Mildew** before applying transfer learning.\n",
        "\n",
        "- **Three Convolutional Layers** → Extract key features efficiently.\n",
        "- **Batch Normalization** → Stabilizes training and improves convergence.\n",
        "- **L2 Regularization (`0.0001`)** → Prevents overfitting without excessive constraint.\n",
        "- **Dropout (`0.3`)** → Enhances generalization by reducing reliance on specific neurons.\n",
        "- **Max Pooling (`2x2`)** → Reduces computational cost while keeping essential patterns.\n",
        "- **Adam Optimizer (`0.001` learning rate)** → Balances speed and stability.\n",
        "- **Sigmoid Activation (Binary Classification)** → Outputs probability for \"Infected\" class.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import (\n",
        "    Conv2D,\n",
        "    MaxPooling2D,\n",
        "    Flatten,\n",
        "    Dense,\n",
        "    Dropout,\n",
        "    BatchNormalization,\n",
        ")\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "\n",
        "def create_base_cnn():\n",
        "    \"\"\"\n",
        "    Creates a simplified CNN model for binary classification.\n",
        "\n",
        "    Improvements:\n",
        "    - Fewer convolutional layers (3 instead of 4) for efficiency\n",
        "    - Uses BatchNormalization after each Conv layer for stability\n",
        "    - Lower dropout rate (0.3 instead of 0.5) to balance regularization\n",
        "    - Learning rate increased to 0.001 for faster convergence\n",
        "    - Less aggressive L2 regularization to reduce training cost\n",
        "\n",
        "    Returns:\n",
        "        model: A compiled Keras CNN model\n",
        "    \"\"\"\n",
        "\n",
        "    model = Sequential(\n",
        "        [\n",
        "            # First convolutional block\n",
        "            Conv2D(\n",
        "                filters=32,\n",
        "                kernel_size=(3, 3),\n",
        "                activation=\"relu\",\n",
        "                input_shape=image_shape,\n",
        "                kernel_regularizer=l2(0.0001),\n",
        "            ),\n",
        "            BatchNormalization(),\n",
        "            MaxPooling2D(pool_size=(2, 2)),\n",
        "            # Second convolutional block\n",
        "            Conv2D(\n",
        "                filters=64,\n",
        "                kernel_size=(3, 3),\n",
        "                activation=\"relu\",\n",
        "                kernel_regularizer=l2(0.0001),\n",
        "            ),\n",
        "            BatchNormalization(),\n",
        "            MaxPooling2D(pool_size=(2, 2)),\n",
        "            # Third convolutional block\n",
        "            Conv2D(\n",
        "                filters=128,\n",
        "                kernel_size=(3, 3),\n",
        "                activation=\"relu\",\n",
        "                kernel_regularizer=l2(0.0001),\n",
        "            ),\n",
        "            BatchNormalization(),\n",
        "            MaxPooling2D(pool_size=(2, 2)),\n",
        "            # Flatten layer to convert feature maps into a single vector\n",
        "            Flatten(),\n",
        "            # Fully connected layer with regularization\n",
        "            Dense(128, activation=\"relu\", kernel_regularizer=l2(0.0001)),\n",
        "            Dropout(0.3),  # Lower dropout for better training\n",
        "            # Output layer for binary classification\n",
        "            Dense(1, activation=\"sigmoid\"),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    # Compile Model\n",
        "    model.compile(\n",
        "        optimizer=Adam(learning_rate=0.001),  # Slightly higher learning rate\n",
        "        loss=\"binary_crossentropy\",\n",
        "        metrics=[\"accuracy\"],\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "# Instantiate the CNN model\n",
        "model_cnn = create_base_cnn()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Model Summary**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Print Model Summary\n",
        "model_cnn.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Train CNN Model with Early Stopping**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Implement EarlyStopping to prevent overfitting**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set EarlyStopping with a lower patience for faster convergence\n",
        "early_stop = EarlyStopping(monitor=\"val_loss\", patience=3, restore_best_weights=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Train the CNN model for 20 epochs**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create the CNN model\n",
        "model = create_base_cnn()\n",
        "\n",
        "# Store the training history\n",
        "history = model.fit(\n",
        "    train_set,\n",
        "    epochs=20,\n",
        "    steps_per_epoch=len(train_set.classes) // batch_size,\n",
        "    validation_data=validation_set,\n",
        "    callbacks=[early_stop],\n",
        "    verbose=1\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Load and Save the CNN Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save the model with the original file name\n",
        "model_cnn.save(\"outputs/v1/mildew_detector_cnn.keras\")\n",
        "print(\"Model saved successfully as 'mildew_detector_cnn.keras'\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Model Performance & Evaluation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Evaluate CNN on the Test Set**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate the model on the test set\n",
        "test_loss, test_accuracy = model.evaluate(test_set)\n",
        "\n",
        "# Print evaluation results\n",
        "print(f\" Test Accuracy: {test_accuracy:.4f}\")\n",
        "print(f\" Test Loss: {test_loss:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Plot Learning Curves**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Convert training history to DataFrame\n",
        "losses = pd.DataFrame(history.history)\n",
        "\n",
        "# Set Seaborn style\n",
        "sns.set_style(\"whitegrid\")\n",
        "\n",
        "# Plot Loss Curve\n",
        "plt.figure(figsize=(6, 4))\n",
        "losses[[\"loss\", \"val_loss\"]].plot(style=\".-\")\n",
        "plt.title(\"Loss Over Epochs\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend([\"Training Loss\", \"Validation Loss\"])\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.savefig(f\"{file_path}/model_training_losses.png\", bbox_inches=\"tight\", dpi=150)\n",
        "plt.show()\n",
        "\n",
        "# Plot Accuracy Curve\n",
        "plt.figure(figsize=(6, 4))\n",
        "losses[[\"accuracy\", \"val_accuracy\"]].plot(style=\".-\")\n",
        "plt.title(\"Accuracy Over Epochs\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend([\"Training Accuracy\", \"Validation Accuracy\"])\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.savefig(f\"{file_path}/model_training_acc.png\", bbox_inches=\"tight\", dpi=150)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Confusion Matrix & Classification Report**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "# Create output directory\n",
        "output_dir = \"outputs/v1\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "\n",
        "def generate_confusion_matrix(y_true, y_pred, label_map, set_name):\n",
        "    \"\"\"\n",
        "    Generates and saves a static confusion matrix.\n",
        "    \"\"\"\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    cm_df = pd.DataFrame(cm, index=label_map, columns=label_map)\n",
        "\n",
        "    # Plot confusion matrix\n",
        "    plt.figure(figsize=(5, 4))\n",
        "    sns.heatmap(cm_df, annot=True, fmt=\"d\", cmap=\"Blues\", linewidths=0.5)\n",
        "    plt.title(f\"Confusion Matrix - {set_name} Set\")\n",
        "    plt.xlabel(\"Predicted Label\")\n",
        "    plt.ylabel(\"True Label\")\n",
        "    plt.tight_layout()\n",
        "\n",
        "    # Save the confusion matrix\n",
        "    save_path = os.path.join(output_dir, f\"confusion_matrix_{set_name.lower()}.png\")\n",
        "    plt.savefig(save_path, dpi=150)\n",
        "    plt.close()  # Prevent multiple displays\n",
        "    print(f\"Confusion Matrix saved: {save_path}\")\n",
        "\n",
        "    return cm\n",
        "\n",
        "\n",
        "def generate_classification_report(y_true, y_pred, label_map, set_name):\n",
        "    \"\"\"\n",
        "    Generates and prints a classification report.\n",
        "    \"\"\"\n",
        "    report = classification_report(y_true, y_pred, target_names=label_map)\n",
        "    print(f\"\\n--- Classification Report: {set_name} Set ---\\n\")\n",
        "    print(report)\n",
        "\n",
        "    # Save report as a text file\n",
        "    report_path = os.path.join(\n",
        "        output_dir, f\"classification_report_{set_name.lower()}.txt\"\n",
        "    )\n",
        "    with open(report_path, \"w\") as f:\n",
        "        f.write(report)\n",
        "    print(f\"Classification report saved: {report_path}\")\n",
        "\n",
        "    return report\n",
        "\n",
        "\n",
        "def evaluate_model(generator, model, label_map, set_name, threshold=0.5):\n",
        "    \"\"\"\n",
        "    Evaluates model performance by generating a confusion matrix and classification report.\n",
        "    \"\"\"\n",
        "    y_true = generator.classes\n",
        "    y_pred_probs = model.predict(generator)\n",
        "    y_pred = (y_pred_probs > threshold).astype(int).flatten()\n",
        "\n",
        "    print(f\"\\n#### {set_name} Set Evaluation ####\\n\")\n",
        "\n",
        "    cm = generate_confusion_matrix(y_true, y_pred, label_map, set_name)\n",
        "    report = generate_classification_report(y_true, y_pred, label_map, set_name)\n",
        "\n",
        "    return cm, report\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get label names from training set\n",
        "label_map = list(train_set.class_indices.keys())\n",
        "\n",
        "# Evaluate on Train, Validation, and Test sets\n",
        "train_cm, train_report = evaluate_model(train_set, model, label_map, \"Train\")\n",
        "val_cm, val_report = evaluate_model(validation_set, model, label_map, \"Validation\")\n",
        "test_cm, test_report = evaluate_model(test_set, model, label_map, \"Test\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **McNemar’s Test for Model Comparison**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "McNemar’s test is used to compare the performance of two classification models on the **same dataset** and determine if their differences in predictions are **statistically significant**.\n",
        "\n",
        "**Why McNemar’s Test?**\n",
        "- **Beyond Accuracy** → Instead of just comparing accuracy scores, it evaluates whether **one model consistently outperforms another** in misclassification cases.\n",
        "- **Paired Comparison** → Since both models predict the same test set, McNemar’s test measures if **their disagreements are random or meaningful**.\n",
        "- **Significance Test** → If the **p-value < 0.05**, the models have a statistically significant difference in performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from statsmodels.stats.contingency_tables import mcnemar\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "output_dir = \"outputs/v1\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "\n",
        "### McNemar’s Test for Model Comparison\n",
        "def mcnemar_test(test_set, model_1, model_2):\n",
        "    \"\"\"\n",
        "    Perform McNemar's test to compare two classification models.\n",
        "    Checks if there is a statistically significant difference between them.\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"\\n### Running McNemar's Test ###\")\n",
        "\n",
        "    # Extract ground-truth labels\n",
        "    y_true = test_set.classes\n",
        "\n",
        "    # Get predictions from both models\n",
        "    y_pred_model_1 = (model_1.predict(test_set) > 0.5).astype(int).flatten()\n",
        "    y_pred_model_2 = (model_2.predict(test_set) > 0.5).astype(int).flatten()\n",
        "\n",
        "    # Compute contingency table\n",
        "    a = np.sum((y_pred_model_1 == y_true) & (y_pred_model_2 == y_true))  # Both correct\n",
        "    b = np.sum(\n",
        "        (y_pred_model_1 == y_true) & (y_pred_model_2 != y_true)\n",
        "    )  # Model 1 correct, Model 2 wrong\n",
        "    c = np.sum(\n",
        "        (y_pred_model_1 != y_true) & (y_pred_model_2 == y_true)\n",
        "    )  # Model 1 wrong, Model 2 correct\n",
        "    d = np.sum((y_pred_model_1 != y_true) & (y_pred_model_2 != y_true))  # Both wrong\n",
        "\n",
        "    contingency_table = np.array([[a, b], [c, d]])\n",
        "    print(\"McNemar's Contingency Table:\\n\", contingency_table)\n",
        "\n",
        "    # Perform McNemar's test\n",
        "    result = mcnemar(contingency_table, exact=False)\n",
        "    print(f\"Chi-square statistic: {result.statistic:.4f}\")\n",
        "    print(f\"P-value: {result.pvalue:.6f}\")\n",
        "\n",
        "    # Interpretation\n",
        "    if result.pvalue < 0.05:\n",
        "        print(\"There is a significant difference between the models.\")\n",
        "    else:\n",
        "        print(\"No significant difference between the models.\")\n",
        "\n",
        "    return result.pvalue"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Model Evaluation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Load Saved Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_path = \"outputs/v1/mildew_detector_mobilenet.keras\"  \n",
        "model = load_model(model_path)\n",
        "print(\"\\nModel loaded successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Evaluate Model Performance**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_loss, test_accuracy = model.evaluate(test_set, verbose=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Save Evaluation Pickle**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "evaluation = {\"test_loss\": test_loss, \"test_accuracy\": test_accuracy}\n",
        "joblib.dump(value=evaluation, filename=f\"{output_dir}/evaluation.pkl\")\n",
        "print(\"\\nModel evaluation results saved!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Check Business Case Requirement**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "required_accuracy = 0.90  # Business goal threshold\n",
        "\n",
        "print(\"\\n### Performance Evaluation Summary ###\")\n",
        "print(f\"Required Accuracy: {required_accuracy * 100:.2f}%\")\n",
        "print(f\"Model Achieved Accuracy: {test_accuracy * 100:.2f}%\\n\")\n",
        "\n",
        "if test_accuracy >= required_accuracy:\n",
        "    print(\"The model meets the business performance requirement.\")\n",
        "else:\n",
        "    print(\"The model does NOT meet the business requirement. Consider further tuning.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Overfitting Analysis** "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Analyze overfitting by comparing training vs. validation accuracy & loss**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "\n",
        "# Convert training history to DataFrame\n",
        "losses = pd.DataFrame(history.history)\n",
        "\n",
        "# Set style for plots\n",
        "sns.set_style(\"whitegrid\")\n",
        "\n",
        "# Plot Training & Validation Loss\n",
        "plt.figure(figsize=(8, 4))\n",
        "plt.plot(losses[\"loss\"], label=\"Training Loss\", marker=\"o\")\n",
        "plt.plot(losses[\"val_loss\"], label=\"Validation Loss\", marker=\"o\")\n",
        "plt.title(\"Loss Curve\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Plot Training & Validation Accuracy\n",
        "plt.figure(figsize=(8, 4))\n",
        "plt.plot(losses[\"accuracy\"], label=\"Training Accuracy\", marker=\"o\")\n",
        "plt.plot(losses[\"val_accuracy\"], label=\"Validation Accuracy\", marker=\"o\")\n",
        "plt.title(\"Accuracy Curve\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Identify Overfitting\n",
        "train_acc = losses[\"accuracy\"].iloc[-1]\n",
        "val_acc = losses[\"val_accuracy\"].iloc[-1]\n",
        "train_loss = losses[\"loss\"].iloc[-1]\n",
        "val_loss = losses[\"val_loss\"].iloc[-1]\n",
        "\n",
        "print(\"\\n### Overfitting Analysis ###\")\n",
        "print(f\"Final Training Accuracy: {train_acc:.4f}\")\n",
        "print(f\"Final Validation Accuracy: {val_acc:.4f}\")\n",
        "print(f\"Final Training Loss: {train_loss:.4f}\")\n",
        "print(f\"Final Validation Loss: {val_loss:.4f}\")\n",
        "\n",
        "# Simple Overfitting Check\n",
        "if train_acc - val_acc > 0.05:  # If training accuracy is much higher than validation\n",
        "    print(\"\\nWarning: Possible Overfitting Detected!\")\n",
        "    print(\n",
        "        \"Consider using Dropout, L2 Regularization, or reducing the number of layers.\"\n",
        "    )\n",
        "else:\n",
        "    print(\"\\nNo significant overfitting detected. The model generalizes well.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Hyperparameter Tuning with Keras Tuner** "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Optimize the CNN model using Keras Tuner to improve performance while preventing overfitting."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Import Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import keras_tuner as kt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import (\n",
        "    Conv2D,\n",
        "    MaxPooling2D,\n",
        "    Flatten,\n",
        "    Dense,\n",
        "    Dropout,\n",
        "    BatchNormalization,\n",
        ")\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Define the Hyperparameter Search Space**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Optimize the following parameters:\n",
        "- Number of Filters → [32, 64]\n",
        "- L2 Regularization (Weight Decay) → [0.0001, 0.001]\n",
        "- Dropout Rate → [0.2, 0.5]\n",
        "- Learning Rate → [0.0001, 0.0005]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Function to define CNN model with hyperparameter tuning\n",
        "def build_model(hp):\n",
        "    \"\"\"\n",
        "    Define a CNN model with hyperparameter tuning using Keras Tuner.\n",
        "\n",
        "    Parameters:\n",
        "    - hp: Keras Tuner search space\n",
        "\n",
        "    Returns:\n",
        "    - Compiled Keras model\n",
        "    \"\"\"\n",
        "    model = Sequential(\n",
        "        [\n",
        "            Conv2D(\n",
        "                filters=hp.Choice(\"num_filters\", values=[32, 64]),\n",
        "                kernel_size=(3, 3),\n",
        "                activation=\"relu\",\n",
        "                input_shape=image_shape,\n",
        "                kernel_regularizer=l2(hp.Choice(\"l2_reg\", values=[0.0001, 0.001])),\n",
        "            ),\n",
        "            BatchNormalization(),\n",
        "            MaxPooling2D(pool_size=(2, 2)),\n",
        "            Conv2D(\n",
        "                filters=hp.Choice(\"num_filters\", values=[32, 64]),\n",
        "                kernel_size=(3, 3),\n",
        "                activation=\"relu\",\n",
        "                kernel_regularizer=l2(hp.Choice(\"l2_reg\", values=[0.0001, 0.001])),\n",
        "            ),\n",
        "            BatchNormalization(),\n",
        "            MaxPooling2D(pool_size=(2, 2)),\n",
        "            Flatten(),\n",
        "            Dense(128, activation=\"relu\"),\n",
        "            Dropout(hp.Choice(\"dropout_rate\", values=[0.2, 0.5])),\n",
        "            Dense(1, activation=\"sigmoid\"),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=Adam(\n",
        "            learning_rate=hp.Choice(\"learning_rate\", values=[0.0001, 0.0005])\n",
        "        ),\n",
        "        loss=\"binary_crossentropy\",\n",
        "        metrics=[\"accuracy\"],\n",
        "    )\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Run Hyperparameter Search**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Search for the best hyperparameters using Keras Tuner’s RandomSearch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define the tuner\n",
        "tuner = kt.RandomSearch(\n",
        "    build_model,\n",
        "    objective=\"val_accuracy\",  # Optimize for highest validation accuracy\n",
        "    max_trials=5,  # Limits the number of model variations\n",
        "    executions_per_trial=1,  # Runs each model once\n",
        "    directory=\"keras_tuner_results\",\n",
        "    project_name=\"cnn_tuning\",\n",
        ")\n",
        "\n",
        "# Run hyperparameter search\n",
        "tuner.search(\n",
        "    train_set,\n",
        "    validation_data=validation_set,\n",
        "    epochs=10,\n",
        "    callbacks=[tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=3)],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "###  **Retrieve Best Hyperparameters & Train Final Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Retrieve best hyperparameters\n",
        "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "\n",
        "print(\"\\n### Best Hyperparameters Found ###\")\n",
        "print(f\"Filters: {best_hps.get('num_filters')}\")\n",
        "print(f\"L2 Regularization: {best_hps.get('l2_reg')}\")\n",
        "print(f\"Dropout Rate: {best_hps.get('dropout_rate')}\")\n",
        "print(f\"Learning Rate: {best_hps.get('learning_rate')}\")\n",
        "\n",
        "# Train the best model\n",
        "best_model = tuner.hypermodel.build(best_hps)\n",
        "history_best = best_model.fit(\n",
        "    train_set,\n",
        "    validation_data=validation_set,\n",
        "    epochs=10,\n",
        "    callbacks=[tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=3)],\n",
        "    verbose=1,\n",
        ")\n",
        "\n",
        "# Save the best model\n",
        "best_model.save(\"outputs/v1/mildew_detector_cnn_tuned.keras\")\n",
        "print(\"\\nBest tuned CNN model saved successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Evaluate the Tuned Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_model = tf.keras.models.load_model(\"outputs/v1/mildew_detector_cnn_tuned.keras\")\n",
        "test_loss, test_accuracy = best_model.evaluate(test_set)\n",
        "\n",
        "print(\"\\n### Tuned Model Evaluation ###\")\n",
        "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
        "print(f\"Test Loss: {test_loss:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Compare Tuned Model vs. Original CNN**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Compare the original CNN with the tuned CNN to check if hyperparameter tuning improved the performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Load Both Models**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Load the original CNN model\n",
        "original_model = load_model(\"outputs/v1/mildew_detector_cnn.keras\")\n",
        "\n",
        "# Load the best tuned CNN model\n",
        "tuned_model = load_model(\"outputs/v1/mildew_detector_cnn_tuned.keras\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Evaluate Both Models on the Test Set**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate Original Model\n",
        "orig_test_loss, orig_test_accuracy = original_model.evaluate(test_set)\n",
        "print(f\"Original CNN Test Accuracy: {orig_test_accuracy:.4f}\")\n",
        "print(f\"Original CNN Test Loss: {orig_test_loss:.4f}\")\n",
        "\n",
        "# Evaluate Tuned Model\n",
        "tuned_test_loss, tuned_test_accuracy = tuned_model.evaluate(test_set)\n",
        "print(f\"Tuned CNN Test Accuracy: {tuned_test_accuracy:.4f}\")\n",
        "print(f\"Tuned CNN Test Loss: {tuned_test_loss:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Compare Accuracy & Loss in a Table**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Create a comparison table\n",
        "comparison_df = pd.DataFrame(\n",
        "    {\n",
        "        \"Model\": [\"Original CNN\", \"Tuned CNN\"],\n",
        "        \"Test Accuracy\": [orig_test_accuracy, tuned_test_accuracy],\n",
        "        \"Test Loss\": [orig_test_loss, tuned_test_loss],\n",
        "    }\n",
        ")\n",
        "\n",
        "# Display results\n",
        "import ace_tools as tools\n",
        "\n",
        "tools.display_dataframe_to_user(name=\"Model Comparison\", dataframe=comparison_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Plot Comparison of Accuracy & Loss**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Data for plotting\n",
        "models = [\"Original CNN\", \"Tuned CNN\"]\n",
        "accuracy_values = [orig_test_accuracy, tuned_test_accuracy]\n",
        "loss_values = [orig_test_loss, tuned_test_loss]\n",
        "\n",
        "# Plot Accuracy Comparison\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.bar(models, accuracy_values, color=[\"blue\", \"green\"])\n",
        "plt.ylabel(\"Test Accuracy\")\n",
        "plt.title(\"Accuracy Comparison: Original vs. Tuned CNN\")\n",
        "plt.ylim(0, 1)\n",
        "plt.show()\n",
        "\n",
        "# Plot Loss Comparison\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.bar(models, loss_values, color=[\"red\", \"purple\"])\n",
        "plt.ylabel(\"Test Loss\")\n",
        "plt.title(\"Loss Comparison: Original vs. Tuned CNN\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Remarks**\n",
        "- Tuned CNN has higher test accuracy: Meaning it generalizes better to unseen data.\n",
        "- Tuned CNN has lower test loss: Meaning it makes more confident and accurate predictions.\n",
        "- Conclusion: The Tuned CNN is better than the original model! "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Transfer Learning with MobileNetV2**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Implement Transfer Learning using MobileNetV2 to see if it performs even better."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Why Use MobileNetV2?**\n",
        "\n",
        "- Pre-trained on ImageNet → Learns faster with fewer data\n",
        "- Efficient & Lightweight → Works well on limited resources (Codespaces)\n",
        "- Better Feature Extraction → Captures high-level patterns in leaf images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Load MobileNetV2 Pretrained Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
        "\n",
        "\n",
        "# Function to create a MobileNetV2 model\n",
        "def create_mobilenet_model(input_shape=(128, 128, 3), num_classes=1):\n",
        "    \"\"\"\n",
        "    Creates a MobileNetV2 model for binary classification.\n",
        "\n",
        "    - Uses a pre-trained MobileNetV2 backbone.\n",
        "    - Freezes base layers to retain pre-trained features.\n",
        "    - Adds a custom classification head.\n",
        "\n",
        "    Parameters:\n",
        "        input_shape (tuple): Shape of input images.\n",
        "        num_classes (int): Number of output classes.\n",
        "\n",
        "    Returns:\n",
        "        model (tf.keras Model): Compiled MobileNetV2 model.\n",
        "    \"\"\"\n",
        "\n",
        "    # Load MobileNetV2 with pre-trained weights, excluding the top layers\n",
        "    base_model = MobileNetV2(\n",
        "        weights=\"imagenet\", include_top=False, input_shape=input_shape\n",
        "    )\n",
        "\n",
        "    # Freeze the base model layers\n",
        "    base_model.trainable = False\n",
        "\n",
        "    # Add custom layers for classification\n",
        "    x = base_model.output\n",
        "    x = GlobalAveragePooling2D()(x)  # Reduce feature map size\n",
        "    x = Dense(128, activation=\"relu\")(x)\n",
        "    x = Dropout(0.3)(x)  # Dropout to prevent overfitting\n",
        "    output_layer = Dense(num_classes, activation=\"sigmoid\")(x)  # Binary classification\n",
        "\n",
        "    # Create the final model\n",
        "    model = Model(inputs=base_model.input, outputs=output_layer)\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "# Instantiate the MobileNetV2 model\n",
        "mobilenet_model = create_mobilenet_model()\n",
        "\n",
        "# Print model summary\n",
        "mobilenet_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Train MobileNetV2**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Define Early Stopping callback\n",
        "early_stop = EarlyStopping(monitor=\"val_loss\", patience=3, restore_best_weights=True)\n",
        "\n",
        "# Train the MobileNetV2 model\n",
        "history_mobilenet = mobilenet_model.fit(\n",
        "    train_set,\n",
        "    epochs=10,  \n",
        "    steps_per_epoch=len(train_set),\n",
        "    validation_data=validation_set,\n",
        "    callbacks=[early_stop],\n",
        "    verbose=1,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Evaluate MobileNetV2 on Test Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate the trained model on the test set\n",
        "test_loss, test_accuracy = mobilenet_model.evaluate(test_set)\n",
        "\n",
        "print(\"\\n### MobileNetV2 Model Evaluation ###\")\n",
        "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
        "print(f\"Test Loss: {test_loss:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Save MobileNetV2 Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mobilenet_model.save(\"outputs/v1/mildew_detector_mobilenet.keras\")\n",
        "print(\"MobileNetV2 Model Saved Successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Compare MobileNetV2 vs. Tuned CNN**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Load the tuned CNN model\n",
        "tuned_model = load_model(\"outputs/v1/mildew_detector_cnn_tuned.keras\")\n",
        "tuned_test_loss, tuned_test_accuracy = tuned_model.evaluate(test_set)\n",
        "\n",
        "# MobileNetV2 test results (already calculated)\n",
        "mobilenet_test_loss, mobilenet_test_accuracy = test_loss, test_accuracy\n",
        "\n",
        "# Create a comparison table\n",
        "comparison_df = pd.DataFrame(\n",
        "    {\n",
        "        \"Model\": [\"Tuned CNN\", \"MobileNetV2\"],\n",
        "        \"Test Accuracy\": [tuned_test_accuracy, mobilenet_test_accuracy],\n",
        "        \"Test Loss\": [tuned_test_loss, mobilenet_test_loss],\n",
        "    }\n",
        ")\n",
        "\n",
        "# Display the comparison\n",
        "print(\"\\n### Model Comparison ###\")\n",
        "print(comparison_df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Visualize Model Performance**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot Accuracy Comparison\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.bar(\n",
        "    [\"Tuned CNN\", \"MobileNetV2\"],\n",
        "    [tuned_test_accuracy, mobilenet_test_accuracy],\n",
        "    color=[\"blue\", \"green\"],\n",
        ")\n",
        "plt.ylabel(\"Test Accuracy\")\n",
        "plt.title(\"Accuracy Comparison: Tuned CNN vs. MobileNetV2\")\n",
        "plt.ylim(0, 1)\n",
        "plt.show()\n",
        "\n",
        "# Plot Loss Comparison\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.bar(\n",
        "    [\"Tuned CNN\", \"MobileNetV2\"],\n",
        "    [tuned_test_loss, mobilenet_test_loss],\n",
        "    color=[\"red\", \"purple\"],\n",
        ")\n",
        "plt.ylabel(\"Test Loss\")\n",
        "plt.title(\"Loss Comparison: Tuned CNN vs. MobileNetV2\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Choose the Best Model & Save for Deployment**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Select the best model based on accuracy\n",
        "if mobilenet_test_accuracy >= tuned_test_accuracy:\n",
        "    final_model_name = \"MobileNetV2\"\n",
        "    final_model_path = \"outputs/v1/mildew_detector_mobilenet.keras\"\n",
        "else:\n",
        "    final_model_name = \"Tuned CNN\"\n",
        "    final_model_path = \"outputs/v1/mildew_detector_cnn_tuned.keras\"\n",
        "\n",
        "# Load and save the best model as the final deployment model\n",
        "final_model = load_model(final_model_path)\n",
        "final_model.save(\"outputs/v1/final_mildew_detector.keras\")\n",
        "\n",
        "print(\"\\n### Final Model Selected ###\")\n",
        "print(f\"Selected Model: {final_model_name}\")\n",
        "print(f\"Model saved at: outputs/v1/final_mildew_detector.keras\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Explainability & Interpretability**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Grad-CAM Visualization**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Helps us understand which parts of the leaf images the model is focusing on when predicting healthy vs. infected leaves."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Import Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "from tf_explain.core.grad_cam import GradCAM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Load the Final Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set output directory for saving Grad-CAM visualization\n",
        "output_dir = \"outputs/v1\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Load the final trained model\n",
        "final_model = load_model(\"outputs/v1/final_mildew_detector.keras\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Select & Display a Sample Image**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Function to select and display a sample image\n",
        "def load_sample_image(test_set, sample_idx=0):\n",
        "    \"\"\"\n",
        "    Select a sample image from the test set and display it.\n",
        "    \"\"\"\n",
        "    test_images, test_labels = next(iter(test_set))  # Get batch of images\n",
        "    sample_image = test_images[sample_idx]  # Select one image\n",
        "    sample_label = test_labels[sample_idx]  # Get its label\n",
        "\n",
        "    # Display the image\n",
        "    plt.imshow(sample_image)\n",
        "    plt.axis(\"off\")\n",
        "    plt.title(f\"Sample Image - {'Healthy' if sample_label == 0 else 'Infected'}\")\n",
        "    plt.show()\n",
        "\n",
        "    return sample_image, sample_label\n",
        "\n",
        "\n",
        "# Load and display a sample image from the test set\n",
        "sample_image, sample_label = load_sample_image(test_set, sample_idx=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Generate Grad-CAM Heatmap**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Function to generate Grad-CAM visualization\n",
        "def generate_gradcam(model, sample_image, layer_name=\"Conv_1\"):\n",
        "    \"\"\"\n",
        "    Generate and display Grad-CAM heatmap for a given image.\n",
        "\n",
        "    Parameters:\n",
        "    - model: Trained model for predictions\n",
        "    - sample_image: Image to analyze\n",
        "    - layer_name: Last convolutional layer for Grad-CAM (default: \"Conv_1\")\n",
        "    \"\"\"\n",
        "    explainer = GradCAM()\n",
        "\n",
        "    # Ensure correct input shape for the model\n",
        "    sample_image = np.expand_dims(sample_image, axis=0)\n",
        "\n",
        "    # Compute Grad-CAM heatmap\n",
        "    heatmap = explainer.explain(\n",
        "        (sample_image, None), model, class_index=0, layer_name=layer_name\n",
        "    )\n",
        "\n",
        "    # Display the heatmap\n",
        "    plt.imshow(heatmap)\n",
        "    plt.axis(\"off\")\n",
        "    plt.title(\"Grad-CAM Heatmap\")\n",
        "    plt.show()\n",
        "\n",
        "    # Save the image\n",
        "    save_path = os.path.join(output_dir, \"grad_cam.png\")\n",
        "    plt.imsave(save_path, heatmap)\n",
        "    print(f\"Grad-CAM visualization saved at: {save_path}\")\n",
        "\n",
        "\n",
        "# Generate and display Grad-CAM heatmap\n",
        "generate_gradcam(final_model, sample_image)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Predict on New Images**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Load & Predict on Sample Image**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load test images and classify them using the trained model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Load the final model\n",
        "model = load_model(\"outputs/v1/final_mildew_detector.keras\")\n",
        "\n",
        "# Select an image by specifying its index (pointer)\n",
        "pointer = 60\n",
        "label = labels[1]  # Selecting an 'Infected' leaf image\n",
        "\n",
        "# Load the selected image and resize it\n",
        "pil_image = image.load_img(\n",
        "    test_path + \"/\" + label + \"/\" + os.listdir(test_path + \"/\" + label)[pointer],\n",
        "    target_size=image_shape,\n",
        "    color_mode=\"rgb\",\n",
        ")\n",
        "\n",
        "# Convert the image to an array and normalize it\n",
        "my_image = image.img_to_array(pil_image) / 255.0\n",
        "my_image = np.expand_dims(my_image, axis=0)  # Add batch dimension\n",
        "\n",
        "# Make a prediction\n",
        "pred_proba = model.predict(my_image)[0, 0]  # Extract prediction probability\n",
        "\n",
        "# Map indices to class labels\n",
        "target_map = {v: k for k, v in train_set.class_indices.items()}  # Reverse mapping\n",
        "pred_class = target_map[int(pred_proba > 0.5)]  # **Fixed: Ensure correct mapping**\n",
        "\n",
        "# Adjust probability if needed\n",
        "if pred_class == target_map[0]:\n",
        "    pred_proba = 1 - pred_proba\n",
        "\n",
        "# Display results\n",
        "print(f\"Image shape: {pil_image.size}\")\n",
        "print(f\"Image mode: {pil_image.mode}\")\n",
        "print(f\"Predicted class: {pred_class}\")\n",
        "print(f\"Prediction probability: {pred_proba:.4f}\")\n",
        "\n",
        "# Show the image\n",
        "pil_image\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Compare Predictions for Multiple Images**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define a list of pointers\n",
        "pointers = [10, 30, 50, 70]\n",
        "label = labels[1]  # 'Infected' or 'Healthy'\n",
        "\n",
        "fig, axes = plt.subplots(1, len(pointers), figsize=(15, 5))\n",
        "\n",
        "for i, pointer in enumerate(pointers):\n",
        "    img_list = os.listdir(test_path + \"/\" + label)\n",
        "\n",
        "    if pointer >= len(img_list):\n",
        "        print(f\"Skipping pointer {pointer}, index out of range.\")\n",
        "        continue\n",
        "\n",
        "    img_path = test_path + \"/\" + label + \"/\" + img_list[pointer]\n",
        "\n",
        "    # Load and preprocess the image\n",
        "    img = image.load_img(img_path, target_size=(128, 128))\n",
        "    img_array = image.img_to_array(img) / 255.0\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "    # Make a prediction\n",
        "    pred = model.predict(img_array)[0, 0]\n",
        "    pred_class = \"Healthy\" if pred < 0.5 else \"Infected\"\n",
        "\n",
        "    # Plot the image and prediction result\n",
        "    axes[i].imshow(img)\n",
        "    axes[i].set_title(f\"{pred_class}\\nProb: {pred:.4f}\")\n",
        "    axes[i].axis(\"off\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Conclusion and Next Steps**\n",
        "---\n",
        "\n",
        "In this project, we successfully developed a machine learning model to detect **Powdery Mildew on Cherry Leaves** with an efficient and **beginner-friendly approach**.\n",
        "\n",
        "### **Key Achievements**\n",
        "- **Baseline CNN Implementation** → Trained a simple CNN model to establish a reference.\n",
        "- **Transfer Learning with MobileNetV2** → Leveraged pre-trained features for better accuracy and efficiency.\n",
        "- **Optimized Hyperparameter Tuning** → Applied a simplified tuning approach to balance performance and computation cost.\n",
        "- **Model Evaluation & Comparison** → Assessed **CNN vs. MobileNetV2** based on accuracy, loss, and efficiency.\n",
        "- **Explainability with Grad-CAM** → Visualized model focus areas for better interpretability.\n",
        "- **Final Model Selection** → MobileNetV2 was chosen due to its superior **accuracy and efficiency**.\n",
        "\n",
        "### **Next Steps: Model Deployment**\n",
        "The next step is to **deploy the final model** in a **user-friendly application** to allow real-time predictions.\n",
        "\n",
        "#### **Deployment Plan**\n",
        "1. **Develop an Interactive Web App** → Users can upload leaf images for classification.\n",
        "2. **Integrate the MobileNetV2 Model** → Load the trained model into the web application.\n",
        "3. **Deploy on a Cloud Platform** → Host the app using **Streamlit** for accessibility.\n",
        "\n",
        "This deployment will enable **real-time detection of powdery mildew**, supporting **efficient and automated plantation management**.\n",
        "\n",
        "---"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
