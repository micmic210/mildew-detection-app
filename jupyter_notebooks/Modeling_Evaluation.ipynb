{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# **Modeling and Evaluation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "- Address Business Requirement 2: Develop a model to determine whether a given leaf is infected with powdery mildew.\n",
        "- Implement machine learning techniques to train and evaluate a classification model with hyperparameter tuning.\n",
        "\n",
        "## Inputs\n",
        "\n",
        "Dataset Directories:\n",
        "\n",
        "- inputs/mildew_dataset_dataset/cherry-leaves/train\n",
        "- inputs/mildew_dataset_dataset/cherry-leaves/test\n",
        "- inputs/mildew_dataset_dataset/cherry-leaves/validation\n",
        "- Image Shape Embeddings: Precomputed embeddings from the Data Visualization Notebook.\n",
        "\n",
        "## Outputs\n",
        "\n",
        "- Image distribution plot for training, validation, and test sets.\n",
        "- Implementation of image augmentation techniques with real-time sample visualization.\n",
        "- Class indices mapping for label interpretation during inference.\n",
        "- Feature scaling and selection pipeline using GridSearchCV.\n",
        "- Optimized model with hyperparameter tuning using GridSearchCV.\n",
        "- Best hyperparameter combination selected through cross-validation.\n",
        "- Trained machine learning model using the best configuration.\n",
        "- Saved trained model for future inference.\n",
        "- Learning curve plot illustrating model performance over epochs.\n",
        "- Model evaluation metrics (Accuracy, Precision, Recall, F1-score) saved as a pickle file.\n",
        "- Confusion matrix and classification report to analyze prediction performance.\n",
        "- Prediction on a randomly selected image from the test set with probability scores.\n",
        "- Multiple image predictions comparing ground truth vs. model predictions.\n",
        "\n",
        "## Additional Comments\n",
        "\n",
        "- This notebook focuses on developing and training a classification model using the structured dataset.\n",
        "- Performance evaluation ensures that the model meets the defined business requirement.\n",
        "- Proper validation and testing procedures ensure model robustness before deployment.\n",
        "- The trained model will serve as the backbone for the mildew detection application, aiding in real-time predictions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqP-UeN-z3i2"
      },
      "source": [
        "### Import Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from matplotlib.image import imread"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Set Up Environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cwd= os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "os.chdir('/workspace/mildew-detection-app')\n",
        "print(\"You set a new current directory\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZfF_j-Bz3i4",
        "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
      },
      "outputs": [],
      "source": [
        "work_dir = os.getcwd()\n",
        "work_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mavJ8DibrcQ"
      },
      "source": [
        "### Set Input Directories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set train, validation and test paths\n",
        "my_data_dir = 'inputs/mildew_dataset/cherry-leaves'\n",
        "train_path = my_data_dir + '/train'\n",
        "val_path = my_data_dir + '/validation'\n",
        "test_path = my_data_dir + '/test'\n",
        "\n",
        "# Verify that the directories exist\n",
        "for path in [train_path, val_path, test_path]:\n",
        "    if not os.path.isdir(path):\n",
        "        raise ValueError(f\"Directory does not exist: {path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Set Output Directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "version = 'v1'\n",
        "file_path = f'outputs/{version}'\n",
        "\n",
        "if 'outputs' in os.listdir(work_dir) and version in os.listdir(work_dir + '/outputs'):\n",
        "    print('Old version is already available create a new version.')\n",
        "    pass\n",
        "else:\n",
        "    os.makedirs(name=file_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Set Labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set the lables for the images\n",
        "labels = os.listdir(train_path)\n",
        "\n",
        "print(\n",
        "    f\"Project Labels: {labels}\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Set Image Shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Import saved image shape embedding\n",
        "import joblib\n",
        "version = 'v1'\n",
        "image_shape = joblib.load(filename=f\"outputs/{version}/image_shape.pkl\")\n",
        "image_shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Number of Images in Train, Test, and Validation Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Initialize dictionary to store dataset statistics\n",
        "data = {\n",
        "    'Set': [],\n",
        "    'Label': [],\n",
        "    'Frequency': []\n",
        "}\n",
        "\n",
        "# Define dataset folders: train, validation, and test\n",
        "folders = ['train', 'validation', 'test']\n",
        "\n",
        "# Iterate through dataset folders and count images per label\n",
        "for folder in folders:\n",
        "    for label in labels:\n",
        "        row = {\n",
        "            'Set': folder,\n",
        "            'Label': label,\n",
        "            'Frequency': int(len(os.listdir(my_data_dir + '/' + folder + '/' + label)))  \n",
        "        }\n",
        "        for key, value in row.items():\n",
        "            data[key].append(value)\n",
        "        print(\n",
        "            f\"* {folder} - {label}: {len(os.listdir(my_data_dir+'/'+ folder + '/' + label))} images\")\n",
        "\n",
        "# Convert the dictionary into a DataFrame\n",
        "df_freq = pd.DataFrame(data)\n",
        "\n",
        "print(\"\\n\")\n",
        "\n",
        "# Set plot style\n",
        "sns.set_style(\"whitegrid\")\n",
        "plt.figure(figsize=(8, 5))\n",
        "\n",
        "# Create a bar chart to show image distribution\n",
        "sns.barplot(data=df_freq, x='Set', y='Frequency', hue='Label')\n",
        "plt.savefig(f'{file_path}/labels_distribution.png',\n",
        "            bbox_inches='tight', dpi=150)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY3l0-AxO93d"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Image data augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFQo3ycuO-v6"
      },
      "source": [
        "### Initialize ImageDataGenerator for data augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "augmented_image_data = ImageDataGenerator(rotation_range=20,\n",
        "                                          width_shift_range=0.10,\n",
        "                                          height_shift_range=0.10,\n",
        "                                          shear_range=0.1,\n",
        "                                          zoom_range=0.1,\n",
        "                                          horizontal_flip=True,\n",
        "                                          vertical_flip=True,\n",
        "                                          fill_mode='nearest',\n",
        "                                          rescale=1./255\n",
        "                                          )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create Augmented Training Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load training images with augmentation\n",
        "batch_size = 20  # Number of images processed in each batch\n",
        "train_set = augmented_image_data.flow_from_directory(train_path,\n",
        "                                                     target_size=image_shape[:2],\n",
        "                                                     color_mode='rgb',\n",
        "                                                     batch_size=batch_size,\n",
        "                                                     class_mode='binary',\n",
        "                                                     shuffle=True\n",
        "                                                     )\n",
        "\n",
        "# Print dataset information\n",
        "print(\"Class indices:\", train_set.class_indices)  # Dictionary mapping labels to indices\n",
        "print(\"Number of classes:\", len(train_set.class_indices))  # Total number of classes\n",
        "print(\"Total number of images in dataset:\", train_set.samples)  # Total number of images (before augmentation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create Augmented Validation Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Preprocessing the validation images: Normalize pixel values to the range [0, 1]\n",
        "validation_set = ImageDataGenerator(rescale=1./255).flow_from_directory(val_path,\n",
        "                                                                        target_size=image_shape[:2],\n",
        "                                                                        color_mode='rgb',\n",
        "                                                                        batch_size=batch_size,\n",
        "                                                                        class_mode='binary',\n",
        "                                                                        shuffle=False\n",
        "                                                                        )\n",
        "\n",
        "# Display class indices (label mapping)\n",
        "print(validation_set.class_indices)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create Augmented Test Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Preprocessing the test images: Normalize pixel values to the range [0, 1]\n",
        "test_set = ImageDataGenerator(rescale=1./255).flow_from_directory(test_path,\n",
        "                                                                  target_size=image_shape[:2],\n",
        "                                                                  color_mode='rgb',\n",
        "                                                                  batch_size=batch_size,\n",
        "                                                                  class_mode='binary',\n",
        "                                                                  shuffle=False\n",
        "                                                                  )\n",
        "\n",
        "# Display class indices (label mapping)\n",
        "print(test_set.class_indices)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Plot Augmented Images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Training Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for _ in range(3):\n",
        "    img, label = next(train_set)\n",
        "    print(img.shape)  # (1,256,256,3)\n",
        "    plt.imshow(img[0])\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Validation Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for _ in range(3):\n",
        "    img, label = next(validation_set)\n",
        "    print(img.shape)  # (1,256,256,3)\n",
        "    plt.imshow(img[0])\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Test Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for _ in range(3):\n",
        "    img, label = next(test_set)\n",
        "    print(img.shape)  # (1,256,256,3)\n",
        "    plt.imshow(img[0])\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Save Class Indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "joblib.dump(value=train_set.class_indices,\n",
        "            filename=f\"{file_path}/class_indices.pkl\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Creation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Import Model Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense, Conv2D, MaxPooling2D"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### CNN Model "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_tf_model():\n",
        "    \"\"\" \n",
        "    Create a CNN model with multiple Conv2D and MaxPooling2D layers.\n",
        "    The model uses different filter sizes and layer structures \n",
        "    to extract features from images.\n",
        "    \"\"\"\n",
        "    \n",
        "    model = Sequential([\n",
        "        Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=image_shape),\n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "        Conv2D(filters=64, kernel_size=(3, 3), activation='relu'),\n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "        Conv2D(filters=128, kernel_size=(3, 3), activation='relu'),\n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "        Conv2D(filters=128, kernel_size=(3, 3), activation='relu'),\n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "        Flatten(),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dropout(0.3),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    \n",
        "    model.compile(loss='binary_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "    \n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Model Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "create_tf_model().summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Train CNN Model Using Early Stopping and Save the Best Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = create_tf_model()\n",
        "model.fit(train_set,\n",
        "          epochs=25,\n",
        "          steps_per_epoch=len(train_set.classes) // batch_size,\n",
        "          validation_data=validation_set,\n",
        "          callbacks=[early_stop],\n",
        "          verbose=1\n",
        "          )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Save Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.save('outputs/v1/mildew_detector_model.keras')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Performance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Model Learning Curve"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "losses = pd.DataFrame(model.history.history)\n",
        "\n",
        "sns.set_style(\"whitegrid\")\n",
        "losses[['loss', 'val_loss']].plot(style='.-')\n",
        "plt.title(\"Loss\")\n",
        "plt.savefig(f'{file_path}/model_training_losses.png',\n",
        "            bbox_inches='tight', dpi=150)\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n\")\n",
        "losses[['accuracy', 'val_accuracy']].plot(style='.-')\n",
        "plt.title(\"Accuracy\")\n",
        "plt.savefig(f'{file_path}/model_training_acc.png',\n",
        "            bbox_inches='tight', dpi=150)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Model Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load Saved Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from keras.models import load_model\n",
        "model = load_model('outputs/v1/mildew_detector_model.keras')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Evaluate model on test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "evaluation = model.evaluate(test_set)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Save Evaluation Pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "joblib.dump(value=evaluation,\n",
        "            filename=f\"outputs/v1/evaluation.pkl\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Confusion Matrix & Evaluation Report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Obtain predictions\n",
        "y_pred = model.predict(test_set)\n",
        "y_pred = (y_pred > 0.5).astype(int)  # Convert probabilities to binary values (1 if > 0.5, otherwise 0)\n",
        "\n",
        "# Obtain true labels\n",
        "y_true = test_set.classes\n",
        "\n",
        "# Classification report\n",
        "print(\"Classification Report:\\n\")\n",
        "print(classification_report(y_true, y_pred, target_names=['Healthy', 'Infected']))\n",
        "\n",
        "# Confusion matrix\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "# Visualization\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=['Healthy', 'Infected'], yticklabels=['Healthy', 'Infected'])\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.savefig(f'{file_path}/confusion_matrix.png', bbox_inches='tight', dpi=150)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Confirm Model Performance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Classification Report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(\"Classification Report:\\n\")\n",
        "print(classification_report(y_true, y_pred, target_names=['Healthy', 'Infected']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Accuracy Comparision Between Training Data And Test Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Evaluation of training data\n",
        "train_evaluation = model.evaluate(train_set)\n",
        "print(f\"Train data accuracy: Loss = {train_evaluation[0]:.4f}, Accuracy = {train_evaluation[1]:.4f}\")\n",
        "\n",
        "# Evaluation of validation data\n",
        "val_evaluation = model.evaluate(validation_set)\n",
        "print(f\"Validation data accuracy: Loss = {val_evaluation[0]:.4f}, Accuracy = {val_evaluation[1]:.4f}\")\n",
        "\n",
        "# Evaluation of test data\n",
        "print(f\"Test data accuracy: Loss = {evaluation[0]:.4f}, Accuracy = {evaluation[1]:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Visualize Learning Curve (Loss & Accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# 学習履歴がない場合はスキップ\n",
        "if 'history' in dir(model) and hasattr(model.history, 'history'):\n",
        "    history_df = pd.DataFrame(model.history.history)\n",
        "\n",
        "    # Loss の可視化\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    plt.plot(history_df[\"loss\"], label=\"Train Loss\")\n",
        "    plt.plot(history_df[\"val_loss\"], label=\"Validation Loss\")\n",
        "    plt.title(\"Loss Curve\")\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    # Accuracy の可視化\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    plt.plot(history_df[\"accuracy\"], label=\"Train Accuracy\")\n",
        "    plt.plot(history_df[\"val_accuracy\"], label=\"Validation Accuracy\")\n",
        "    plt.title(\"Accuracy Curve\")\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.ylabel(\"Accuracy\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "     "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Prevention Method for Overfitting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "データ拡張(Data Augmentation)\n",
        "Dropout レイヤーの追加\n",
        "L2正則化(Weight Decay)\n",
        "学習率を小さくする"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "① 基準モデルの評価"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluation on baseline model\n",
        "baseline_evaluation = model.evaluate(validation_set)\n",
        "print(f\"Baseline Validation Loss: {baseline_evaluation[0]:.4f}\")\n",
        "print(f\"Baseline Validation Accuracy: {baseline_evaluation[1]:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Data Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "\n",
        "def create_tf_model():\n",
        "    \"\"\"\n",
        "    CNN モデルを作成する関数\n",
        "    \"\"\"\n",
        "    model = Sequential([\n",
        "        Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=(128, 128, 3)),\n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "        Conv2D(filters=64, kernel_size=(3, 3), activation='relu'),\n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "        Conv2D(filters=128, kernel_size=(3, 3), activation='relu'),\n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "        Flatten(),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dropout(0.3),\n",
        "        Dense(1, activation='sigmoid')  # 2クラス分類\n",
        "    ])\n",
        "\n",
        "    model.compile(loss='binary_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Define EarlyStopping callbacks\n",
        "early_stop = EarlyStopping(\n",
        "    monitor='val_loss',  \n",
        "    patience=5,          \n",
        "    restore_best_weights=True  \n",
        ")\n",
        "\n",
        "print(\"Early_stop is defined.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create a lighter model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def create_tf_model():\n",
        "    model = Sequential([\n",
        "        Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=(128, 128, 3)),\n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "        Conv2D(filters=64, kernel_size=(3, 3), activation='relu'),\n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "        Conv2D(filters=128, kernel_size=(3, 3), activation='relu'),\n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "        Flatten(),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dropout(0.3),\n",
        "        Dense(1, activation='sigmoid')  \n",
        "    ])\n",
        "\n",
        "    model.compile(loss='binary_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "model = create_tf_model()\n",
        "\n",
        "history_aug = model.fit(\n",
        "    train_set_aug,\n",
        "    validation_data=validation_set,\n",
        "    epochs=10, \n",
        "    callbacks=[early_stop]\n",
        ")\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate baseline model \n",
        "baseline_evaluation = model.evaluate(validation_set)\n",
        "print(f\"Baseline Validation Loss: {baseline_evaluation[0]:.4f}\")\n",
        "print(f\"Baseline Validation Accuracy: {baseline_evaluation[1]:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ✅ Enhance data augmentation\n",
        "augmented_image_data = ImageDataGenerator(\n",
        "    rotation_range=30,  # Rotation angle\n",
        "    width_shift_range=0.2,  # Horizontal shift\n",
        "    height_shift_range=0.2,  # Vertical shift\n",
        "    shear_range=0.2,  # Shear transformation\n",
        "    zoom_range=0.3,  # Zoom\n",
        "    brightness_range=[0.5, 1.5],  # Brightness adjustment\n",
        "    horizontal_flip=True,  # Horizontal flip\n",
        "    vertical_flip=True,  # Vertical flip\n",
        "    fill_mode='nearest',  # Fill mode\n",
        "    rescale=1./255  # Normalize pixel values\n",
        ")\n",
        "\n",
        "# ✅ Apply modified data augmentation and create a new dataset\n",
        "train_set_aug = augmented_image_data.flow_from_directory(\n",
        "    train_path,  # Directory of training data\n",
        "    target_size=image_shape[:2],  # Target image size\n",
        "    batch_size=batch_size,  # Batch size\n",
        "    class_mode='binary',  # Classification mode (binary classification)\n",
        "    shuffle=True  # Shuffle data\n",
        ")\n",
        "\n",
        "# ✅ Retrain the model with modified data augmentation\n",
        "model = create_tf_model()  # Create model\n",
        "history_aug = model.fit(\n",
        "    train_set_aug,  # Augmented training data\n",
        "    validation_data=validation_set,  # Validation data\n",
        "    epochs=10,  # Experiment with 10 epochs first\n",
        "    callbacks=[early_stop]  # Apply early stopping\n",
        ")\n",
        "\n",
        "# ✅ Evaluate the new model\n",
        "aug_evaluation = model.evaluate(validation_set)  # Evaluate on validation data\n",
        "print(f\"Data Augmentation Validation Loss: {aug_evaluation[0]:.4f}\")\n",
        "print(f\"Data Augmentation Validation Accuracy: {aug_evaluation[1]:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### L2　Regularization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.regularizers import l2\n",
        "\n",
        "def create_tf_model_l2():\n",
        "    model = Sequential([\n",
        "        Conv2D(filters=32, kernel_size=(3, 3), activation='relu',\n",
        "               kernel_regularizer=l2(0.01), input_shape=(128, 128, 3)),\n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "        Conv2D(filters=64, kernel_size=(3, 3), activation='relu', kernel_regularizer=l2(0.01)),\n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "        Flatten(),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dropout(0.3),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "    model.compile(loss='binary_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "# ✅ Retrain the model with L2 regularization\n",
        "model_l2 = create_tf_model_l2()\n",
        "history_l2 = model_l2.fit(\n",
        "    train_set_aug,  # Dataset after data augmentation\n",
        "    validation_data=validation_set,\n",
        "    epochs=10,\n",
        "    callbacks=[early_stop]\n",
        ")\n",
        "\n",
        "# ✅ Evaluate the L2 regularization model\n",
        "l2_evaluation = model_l2.evaluate(validation_set)\n",
        "print(f\"L2 Regularization Validation Loss: {l2_evaluation[0]:.4f}\")\n",
        "print(f\"L2 Regularization Validation Accuracy: {l2_evaluation[1]:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_tf_model_dropout():\n",
        "    model = Sequential([\n",
        "        Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=image_shape),\n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "        Conv2D(filters=64, kernel_size=(3, 3), activation='relu'),\n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "        Flatten(),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dropout(0.5),  # Increase dropout to 50%\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "    model.compile(loss='binary_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "# ✅ Retrain the model with an increased dropout rate\n",
        "model_dropout = create_tf_model_dropout()\n",
        "history_dropout = model_dropout.fit(\n",
        "    train_set_aug,\n",
        "    validation_data=validation_set,\n",
        "    epochs=10,\n",
        "    callbacks=[early_stop]\n",
        ")\n",
        "\n",
        "# ✅ Evaluate the dropout model\n",
        "dropout_evaluation = model_dropout.evaluate(validation_set)\n",
        "print(f\"Dropout (0.5) Validation Loss: {dropout_evaluation[0]:.4f}\")\n",
        "print(f\"Dropout (0.5) Validation Accuracy: {dropout_evaluation[1]:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Improved Model with Overfitting Countermeasures\n",
        "\n",
        "Based on data augmentation, the following adjustments are applied:\n",
        "- Added Dropout (0.3) to prevent overfitting.\n",
        "- Applied L2 regularization (λ=0.001) to suppress overfitting.\n",
        "- Adjusted learning rate to 0.0005 for improved stability.\n",
        "- Increased the number of epochs (20 epochs) to allow the model to converge."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Adjust learning rate to 0.0005\n",
        "learning_rate = 0.0005\n",
        "\n",
        "# Apply L2 regularization (λ=0.001)\n",
        "regularizer = l2(0.001)\n",
        "\n",
        "# Optimized CNN model\n",
        "def create_optimized_model():\n",
        "    model = Sequential([\n",
        "        Conv2D(32, (3, 3), activation='relu', kernel_regularizer=regularizer, input_shape=image_shape),\n",
        "        MaxPooling2D((2, 2)),\n",
        "\n",
        "        Conv2D(64, (3, 3), activation='relu', kernel_regularizer=regularizer),\n",
        "        MaxPooling2D((2, 2)),\n",
        "\n",
        "        Conv2D(128, (3, 3), activation='relu', kernel_regularizer=regularizer),\n",
        "        MaxPooling2D((2, 2)),\n",
        "\n",
        "        Flatten(),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dropout(0.3),  # Apply Dropout(0.3)\n",
        "        Dense(1, activation='sigmoid')  # Binary classification\n",
        "    ])\n",
        "\n",
        "    model.compile(\n",
        "        loss='binary_crossentropy',\n",
        "        optimizer=Adam(learning_rate=learning_rate),  # Adjust learning rate\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "# Check model structure\n",
        "optimized_model = create_optimized_model()\n",
        "optimized_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Image Data Augmentation\n",
        "augmented_image_data = ImageDataGenerator(\n",
        "    rotation_range=30,\n",
        "    width_shift_range=0.15,\n",
        "    height_shift_range=0.15,\n",
        "    shear_range=0.15,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest',\n",
        "    rescale=1./255  # Normalization\n",
        ")\n",
        "\n",
        "# Load data with augmentation applied\n",
        "batch_size = 20\n",
        "train_set_aug = augmented_image_data.flow_from_directory(\n",
        "    train_path,\n",
        "    target_size=image_shape[:2],\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary',\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "# Validation data (without Data Augmentation)\n",
        "validation_set = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
        "    val_path,\n",
        "    target_size=image_shape[:2],\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "# Test data (without Data Augmentation)\n",
        "test_set = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
        "    test_path,\n",
        "    target_size=image_shape[:2],\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary',\n",
        "    shuffle=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "\n",
        "history = optimized_model.fit(\n",
        "    train_set_aug,\n",
        "    validation_data=validation_set,\n",
        "    epochs=20,  \n",
        "    callbacks=[early_stop],\n",
        "    verbose=1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# ✅ 学習履歴の DataFrame 作成\n",
        "history_df = pd.DataFrame(history.history)\n",
        "\n",
        "# ✅ Loss 曲線\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(history_df[\"loss\"], label=\"Train Loss\")\n",
        "plt.plot(history_df[\"val_loss\"], label=\"Validation Loss\")\n",
        "plt.title(\"Loss Curve\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# ✅ Accuracy 曲線\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(history_df[\"accuracy\"], label=\"Train Accuracy\")\n",
        "plt.plot(history_df[\"val_accuracy\"], label=\"Validation Accuracy\")\n",
        "plt.title(\"Accuracy Curve\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate on test data\n",
        "evaluation = optimized_model.evaluate(test_set)\n",
        "\n",
        "print(f\"Final test results: Loss = {evaluation[0]:.4f}, Accuracy = {evaluation[1]:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Improved Model: Overfitting Prevention & Generalization Performance Enhancement\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Adjusted Parameters\n",
        "learning_rate = 0.0003  # Further adjust the learning rate\n",
        "regularizer = l2(0.0005)  # Relax L2 regularization\n",
        "dropout_rate = 0.4  # Increase Dropout to 0.4\n",
        "\n",
        "# Further Optimized CNN Model\n",
        "def create_further_optimized_model():\n",
        "    model = Sequential([\n",
        "        Conv2D(32, (3, 3), activation='relu', kernel_regularizer=regularizer, input_shape=image_shape),\n",
        "        MaxPooling2D((2, 2)),\n",
        "\n",
        "        Conv2D(64, (3, 3), activation='relu', kernel_regularizer=regularizer),\n",
        "        MaxPooling2D((2, 2)),\n",
        "\n",
        "        Conv2D(128, (3, 3), activation='relu', kernel_regularizer=regularizer),\n",
        "        MaxPooling2D((2, 2)),\n",
        "\n",
        "        Flatten(),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dropout(dropout_rate),  # Adjust Dropout to 0.4\n",
        "        Dense(1, activation='sigmoid')  # Binary classification\n",
        "    ])\n",
        "\n",
        "    model.compile(\n",
        "        loss='binary_crossentropy',\n",
        "        optimizer=Adam(learning_rate=learning_rate),  # Adjust learning rate\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "# Check Model Structure\n",
        "further_optimized_model = create_further_optimized_model()\n",
        "further_optimized_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Image Data Augmentation\n",
        "augmented_image_data = ImageDataGenerator(\n",
        "    rotation_range=40,  # Increase rotation range\n",
        "    width_shift_range=0.2,  # Increase horizontal shift\n",
        "    height_shift_range=0.2,  # Increase vertical shift\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.3,  # Increase zoom variation\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest',\n",
        "    rescale=1./255  # Normalization\n",
        ")\n",
        "\n",
        "# Load data with augmentation applied\n",
        "batch_size = 20\n",
        "train_set_aug = augmented_image_data.flow_from_directory(\n",
        "    train_path,\n",
        "    target_size=image_shape[:2],\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary',\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "# Validation data (without Data Augmentation)\n",
        "validation_set = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
        "    val_path,\n",
        "    target_size=image_shape[:2],\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "# Test data (without Data Augmentation)\n",
        "test_set = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
        "    test_path,\n",
        "    target_size=image_shape[:2],\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary',\n",
        "    shuffle=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# EarlyStopping (Prevents Overfitting)\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "# Train the Model\n",
        "history_further = further_optimized_model.fit(\n",
        "    train_set_aug,\n",
        "    validation_data=validation_set,\n",
        "    epochs=30,  # Increased to 30 epochs\n",
        "    callbacks=[early_stop],\n",
        "    verbose=1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# Create a DataFrame for training history\n",
        "history_df = pd.DataFrame(history_further.history)\n",
        "\n",
        "# Loss Curve\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(history_df[\"loss\"], label=\"Train Loss\")\n",
        "plt.plot(history_df[\"val_loss\"], label=\"Validation Loss\")\n",
        "plt.title(\"Loss Curve\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Accuracy Curve\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(history_df[\"accuracy\"], label=\"Train Accuracy\")\n",
        "plt.plot(history_df[\"val_accuracy\"], label=\"Validation Accuracy\")\n",
        "plt.title(\"Accuracy Curve\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate on test data\n",
        "evaluation_further = further_optimized_model.evaluate(test_set)\n",
        "\n",
        "print(f\"Final test results: Loss = {evaluation_further[0]:.4f}, Accuracy = {evaluation_further[1]:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Statistical Testing (t-test or Chi-square test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Step 1: t-test (Testing the Difference in Means)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from scipy.stats import ttest_ind\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
        "import os\n",
        "\n",
        "# Paths to image data (retrieved from the test set)\n",
        "test_healthy_dir = \"/content/mildew_project/inputs/mildew_dataset/cherry-leaves/test/Healthy\"\n",
        "test_infected_dir = \"/content/mildew_project/inputs/mildew_dataset/cherry-leaves/test/Infected\"\n",
        "\n",
        "# List of images (50 from each class)\n",
        "healthy_images = [os.path.join(test_healthy_dir, img) for img in os.listdir(test_healthy_dir)[:50]]\n",
        "infected_images = [os.path.join(test_infected_dir, img) for img in os.listdir(test_infected_dir)[:50]]\n",
        "\n",
        "# Convert images to NumPy arrays (convert to grayscale and extract brightness values)\n",
        "def preprocess_grayscale(image_path, target_size=(128, 128)):\n",
        "    img = load_img(image_path, target_size=target_size, color_mode=\"grayscale\")\n",
        "    img_array = img_to_array(img) / 255.0  # Normalize\n",
        "    return img_array.flatten()  # Flatten to 1D\n",
        "\n",
        "# Create lists of image data\n",
        "healthy_data = np.array([preprocess_grayscale(img) for img in healthy_images])\n",
        "infected_data = np.array([preprocess_grayscale(img) for img in infected_images])\n",
        "\n",
        "# Calculate the mean pixel value\n",
        "healthy_mean = healthy_data.mean()\n",
        "infected_mean = infected_data.mean()\n",
        "\n",
        "# Perform t-test (test whether the means of the two distributions are statistically different)\n",
        "t_stat, p_value = ttest_ind(healthy_data.flatten(), infected_data.flatten())\n",
        "\n",
        "# Display results\n",
        "print(f\"Healthy Mean Brightness: {healthy_mean:.4f}\")\n",
        "print(f\"Infected Mean Brightness: {infected_mean:.4f}\")\n",
        "print(f\"t-statistic: {t_stat:.4f}\")\n",
        "print(f\"p-value: {p_value:.4e}\")\n",
        "\n",
        "# Interpretation of test results\n",
        "alpha = 0.05  # Significance level\n",
        "if p_value < alpha:\n",
        "    print(\"There is a significant difference (Healthy and Infected are statistically different).\")\n",
        "else:\n",
        "    print(\"No statistically significant difference (The mean brightness of the two classes is similar).\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Step 2: Chi-Square Test (Difference in Feature Distribution)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 2: Chi-Square Test (Difference in Feature Distribution)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import chi2_contingency\n",
        "\n",
        "# Create Histogram\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.hist(healthy_data.flatten(), bins=30, alpha=0.7, label=\"Healthy\", color=\"blue\", density=True)\n",
        "plt.hist(infected_data.flatten(), bins=30, alpha=0.7, label=\"Infected\", color=\"red\", density=True)\n",
        "plt.xlabel(\"Pixel Intensity\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.legend()\n",
        "plt.title(\"Histogram of Pixel Intensity (Healthy vs Infected)\")\n",
        "plt.show()\n",
        "\n",
        "# Perform Chi-Square Test (Statistically test for distribution differences)\n",
        "hist_healthy, _ = np.histogram(healthy_data.flatten(), bins=30)\n",
        "hist_infected, _ = np.histogram(infected_data.flatten(), bins=30)\n",
        "chi2_stat, chi2_p_value, _, _ = chi2_contingency([hist_healthy, hist_infected])\n",
        "\n",
        "# Display Results\n",
        "print(f\"Chi-Square Statistic: {chi2_stat:.4f}\")\n",
        "print(f\"p-value: {chi2_p_value:.4e}\")\n",
        "\n",
        "if chi2_p_value < alpha:\n",
        "    print(\"Healthy and Infected have statistically different distributions.\")\n",
        "else:\n",
        "    print(\"No significant difference in distribution.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### PCA "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.decomposition import PCA\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "# Image folder for PCA analysis\n",
        "test_healthy_dir = \"/content/mildew_project/inputs/mildew_dataset/cherry-leaves/test/Healthy\"\n",
        "test_infected_dir = \"/content/mildew_project/inputs/mildew_dataset/cherry-leaves/test/Infected\"\n",
        "\n",
        "# Image size (reduced to lower PCA computation cost)\n",
        "img_size = (32, 32)\n",
        "\n",
        "# List for image data\n",
        "X = []\n",
        "labels = []\n",
        "\n",
        "# Load images, resize, and convert to 1D vector\n",
        "def load_images(folder, label):\n",
        "    for filename in os.listdir(folder)[:100]:  # Limit to 100 images per class to reduce computation cost\n",
        "        img_path = os.path.join(folder, filename)\n",
        "        img = image.load_img(img_path, target_size=img_size, color_mode='grayscale')  # Convert to grayscale\n",
        "        img_array = image.img_to_array(img).flatten()  # Flatten to a 1D vector\n",
        "        X.append(img_array)\n",
        "        labels.append(label)\n",
        "\n",
        "# Load images\n",
        "load_images(test_healthy_dir, \"Healthy\")\n",
        "load_images(test_infected_dir, \"Infected\")\n",
        "\n",
        "# Convert to NumPy array\n",
        "X = np.array(X)\n",
        "labels = np.array(labels)\n",
        "\n",
        "# Apply PCA (reduce to 2 dimensions)\n",
        "pca = PCA(n_components=2)\n",
        "X_pca = pca.fit_transform(X)\n",
        "\n",
        "# Visualize results\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.scatterplot(x=X_pca[:, 0], y=X_pca[:, 1], hue=labels, palette={\"Healthy\": \"blue\", \"Infected\": \"red\"}, alpha=0.7)\n",
        "plt.xlabel(\"Principal Component 1\")\n",
        "plt.ylabel(\"Principal Component 2\")\n",
        "plt.title(\"PCA Visualization of Leaf Images\")\n",
        "plt.legend(title=\"Class\")\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### t-SNE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.manifold import TSNE\n",
        "\n",
        "# Apply t-SNE (reduce to 2 dimensions)\n",
        "tsne = TSNE(n_components=2, perplexity=30, random_state=42)\n",
        "X_tsne = tsne.fit_transform(X)\n",
        "\n",
        "# Visualize results\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.scatterplot(x=X_tsne[:, 0], y=X_tsne[:, 1], hue=labels, palette={\"Healthy\": \"blue\", \"Infected\": \"red\"}, alpha=0.7)\n",
        "plt.xlabel(\"t-SNE Component 1\")\n",
        "plt.ylabel(\"t-SNE Component 2\")\n",
        "plt.title(\"t-SNE Visualization of Leaf Images\")\n",
        "plt.legend(title=\"Class\")\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1. Adjusting t-SNE Parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " Experiment with different values of perplexity (default is 30, try values like 10 or 50)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "tsne = TSNE(n_components=2, perplexity=50, random_state=42)\n",
        "X_tsne = tsne.fit_transform(X)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2. Checking the Contribution of Principal Components (PCA only)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "explained_variance = pca.explained_variance_ratio_\n",
        "plt.bar(range(len(explained_variance)), explained_variance)\n",
        "plt.xlabel(\"Principal Components\")\n",
        "plt.ylabel(\"Explained Variance Ratio\")\n",
        "plt.title(\"Explained Variance of PCA Components\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Feature Selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.feature_selection import SelectKBest, chi2\n",
        "\n",
        "# Data Preprocessing (Rescaling)\n",
        "datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Set the Data Path\n",
        "train_path = \"/content/mildew_project/inputs/mildew_dataset/cherry-leaves/train\"\n",
        "\n",
        "# Create `train_set`\n",
        "batch_size = 20  # Number of images processed at once\n",
        "image_size = (128, 128)  # Image size\n",
        "\n",
        "train_set = datagen.flow_from_directory(\n",
        "    train_path,\n",
        "    target_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary',  # Binary classification (2 classes)\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "# Retrieve Image Data (`X`) and Labels (`y`)\n",
        "X, y = [], []\n",
        "for _ in range(len(train_set)):\n",
        "    img_batch, label_batch = next(train_set)\n",
        "    X.extend(img_batch)  # Append image data to the list\n",
        "    y.extend(label_batch)  # Append labels to the list\n",
        "\n",
        "X = np.array(X)  # Convert to NumPy array\n",
        "y = np.array(y)  # Convert labels to NumPy array\n",
        "\n",
        "# Convert Image Data into a 2D Matrix (Flatten)\n",
        "X_flat = X.reshape(len(X), -1)  # (num_samples, height*width*channels)\n",
        "\n",
        "# Perform Chi-square Test (Select Top 50 Important Features)\n",
        "k = 50\n",
        "chi2_selector = SelectKBest(chi2, k=k)\n",
        "X_kbest = chi2_selector.fit_transform(X_flat, y)\n",
        "\n",
        "# Scores of the Selected Features\n",
        "chi2_scores = chi2_selector.scores_\n",
        "\n",
        "# Visualize the Top 50 Features (Bar Graph)\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.bar(range(k), chi2_scores[:k], color=\"blue\")\n",
        "plt.xlabel(\"Feature Index\")\n",
        "plt.ylabel(\"Chi-square Score\")\n",
        "plt.title(\"Top 50 Features Selected by Chi-square Test\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Predict on New Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Load a Random Image as PIL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "# Select an image by specifying its index (pointer)\n",
        "pointer = 60\n",
        "label = labels[1]  # Selecting an 'Infected' leaf image\n",
        "\n",
        "# Load the selected image from the test dataset and resize it to match the model's input size\n",
        "pil_image = image.load_img(test_path + '/' + label + '/' + os.listdir(test_path+'/' + label)[pointer],\n",
        "                           target_size=image_shape, color_mode='rgb')\n",
        "\n",
        "# Convert the image to an array and normalize pixel values to [0, 1] range\n",
        "my_image = image.img_to_array(pil_image) / 255.0  \n",
        "my_image = np.expand_dims(my_image, axis=0)  # Add batch dimension\n",
        "\n",
        "# Make a prediction using the trained model\n",
        "pred_proba = model.predict(my_image)[0, 0]  # Extract prediction probability\n",
        "\n",
        "# Convert prediction probability to class label\n",
        "target_map = {v: k for k, v in train_set.class_indices.items()}  # Mapping indices to class labels\n",
        "pred_class = target_map[pred_proba > 0.5]  # Determine the predicted class\n",
        "\n",
        "# Ensure probability is adjusted for correct class interpretation\n",
        "if pred_class == target_map[0]:  \n",
        "    pred_proba = 1 - pred_proba  \n",
        "\n",
        "# Display the prediction results\n",
        "print(f'Image shape: {pil_image.size}')  # Display the original image size\n",
        "print(f'Image mode: {pil_image.mode}')  # Display the color mode (e.g., RGB)\n",
        "print(f'Predicted class: {pred_class}')  # Show the predicted class (Healthy or Infected)\n",
        "print(f'Prediction probability: {pred_proba:.4f}')  # Show the confidence level of the prediction\n",
        "\n",
        "# Show the original image\n",
        "pil_image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Compare Predictions for Multiple Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define a list of pointers to check multiple images\n",
        "pointers = [10, 30, 50, 70]  # Compare multiple images\n",
        "label = labels[1]  # 'Infected' (or 'Healthy')\n",
        "\n",
        "fig, axes = plt.subplots(1, len(pointers), figsize=(15, 5))\n",
        "\n",
        "for i, pointer in enumerate(pointers):\n",
        "    img_list = os.listdir(test_path + '/' + label)\n",
        "    if pointer >= len(img_list):\n",
        "        print(f\"Skipping pointer {pointer}, index out of range.\")\n",
        "        continue\n",
        "\n",
        "    img_path = test_path + '/' + label + '/' + img_list[pointer]\n",
        "\n",
        "    # Load and preprocess the image\n",
        "    img = image.load_img(img_path, target_size=(128, 128))\n",
        "    img_array = image.img_to_array(img) / 255.0\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "    # Make a prediction\n",
        "    pred = model.predict(img_array)[0, 0]\n",
        "    pred_class = \"Healthy\" if pred < 0.5 else \"Infected\"\n",
        "\n",
        "    # Plot the image and prediction result\n",
        "    axes[i].imshow(img)\n",
        "    axes[i].set_title(f\"{pred_class}\\nProb: {pred:.4f}\")\n",
        "    axes[i].axis(\"off\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Convolutional Layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Visualizing Filter Responses This will help you see what the convolutional filters are learning by applying them to random noise."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Get the first convolutional layer\n",
        "first_conv_layer = model.get_layer(\"conv2d_4\")  # Change this if needed\n",
        "\n",
        "# Extract weights (filters)\n",
        "filters, biases = first_conv_layer.get_weights()\n",
        "\n",
        "# Normalize filter values to 0-1 for visualization\n",
        "filters = (filters - filters.min()) / (filters.max() - filters.min())\n",
        "\n",
        "# Plot the filters\n",
        "fig, axes = plt.subplots(4, 8, figsize=(12, 6))  # Adjust for the number of filters\n",
        "for i in range(4):\n",
        "    for j in range(8):\n",
        "        ax = axes[i, j]\n",
        "        ax.imshow(filters[:, :, :, i*8+j], cmap=\"viridis\")  # Change the index as needed\n",
        "        ax.axis(\"off\")\n",
        "\n",
        "plt.suptitle(\"Filters of the First Convolutional Layer\")\n",
        "plt.show()\n",
        "     "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Occlusion Sensitivity (Masking Parts of the Image)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "different parts of an image and see how the model’s confidence changes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import cv2\n",
        "\n",
        "def occlusion_sensitivity(model, img_array, patch_size=20, stride=10):\n",
        "    \"\"\"\n",
        "    Creates an occlusion sensitivity map by covering parts of the image\n",
        "    and checking how the model's prediction changes.\n",
        "    \"\"\"\n",
        "    img_height, img_width, _ = img_array.shape[1:]\n",
        "\n",
        "    # Get original prediction\n",
        "    orig_pred = model.predict(img_array)[0, 0]  # Get probability\n",
        "\n",
        "    # Create an empty sensitivity map\n",
        "    sensitivity_map = np.zeros((img_height, img_width))\n",
        "\n",
        "    # Loop over image and apply occlusion\n",
        "    for y in range(0, img_height, stride):\n",
        "        for x in range(0, img_width, stride):\n",
        "            occluded_img = img_array.copy()\n",
        "            occluded_img[:, y:y+patch_size, x:x+patch_size, :] = 0  # Black out a region\n",
        "\n",
        "            # Get new prediction\n",
        "            new_pred = model.predict(occluded_img)[0, 0]\n",
        "\n",
        "            # Store absolute difference\n",
        "            sensitivity_map[y:y+patch_size, x:x+patch_size] = abs(orig_pred - new_pred)\n",
        "\n",
        "    return sensitivity_map\n",
        "\n",
        "# Generate occlusion map\n",
        "sensitivity_map = occlusion_sensitivity(model, img_array)\n",
        "\n",
        "# Plot occlusion sensitivity map\n",
        "plt.figure(figsize=(6, 6))\n",
        "plt.imshow(sensitivity_map, cmap=\"hot\")\n",
        "plt.colorbar()\n",
        "plt.title(\"Occlusion Sensitivity Map\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Compare Feature Visualizations for Healthy VS Infected leaves"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Step 1: Select one healthy and one infected image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import random\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "# Select one healthy and one infected image randomly\n",
        "healthy_image_path = random.choice(os.listdir(test_path + \"/Healthy\"))\n",
        "infected_image_path = random.choice(os.listdir(test_path + \"/Infected\"))\n",
        "\n",
        "# Load and preprocess images\n",
        "def load_and_preprocess(img_path, label):\n",
        "    img = image.load_img(test_path + f\"/{label}/\" + img_path, target_size=image_shape)\n",
        "    img_array = image.img_to_array(img) / 255.0  # Normalize\n",
        "    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
        "    return img, img_array\n",
        "\n",
        "# Load images\n",
        "healthy_pil, healthy_img_array = load_and_preprocess(healthy_image_path, \"Healthy\")\n",
        "infected_pil, infected_img_array = load_and_preprocess(infected_image_path, \"Infected\")\n",
        "\n",
        "# Display selected images\n",
        "plt.figure(figsize=(8, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.imshow(healthy_pil)\n",
        "plt.title(\"Healthy Leaf\")\n",
        "plt.axis(\"off\")\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.imshow(infected_pil)\n",
        "plt.title(\"Infected Leaf\")\n",
        "plt.axis(\"off\")\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Step 2: Generate Filter Visualizations for Both"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract features from the first convolutional layer\n",
        "first_conv_layer = model.get_layer(index=0)  # First Conv2D layer\n",
        "filters, biases = first_conv_layer.get_weights()\n",
        "\n",
        "# Normalize filter values for visualization\n",
        "filters = (filters - filters.min()) / (filters.max() - filters.min())\n",
        "\n",
        "# Function to visualize filters\n",
        "def plot_filters(filters, title):\n",
        "    fig, axes = plt.subplots(4, 8, figsize=(12, 6))\n",
        "    for i, ax in enumerate(axes.flat):\n",
        "        ax.imshow(filters[:, :, :, i], cmap=\"viridis\")\n",
        "        ax.axis(\"off\")\n",
        "    plt.suptitle(title)\n",
        "    plt.show()\n",
        "\n",
        "# Plot filters for comparison\n",
        "plot_filters(filters, \"Filters of the First Conv Layer (Healthy vs Infected)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Step 3: Generate Occlusion Sensitivity Maps"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This will highlight the most important regions in each leaf image.\n",
        "下記のコードは計算コストがかかりすぎるのでライトバージョンが必要。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def occlusion_sensitivity_map(model, img_array, patch_size=10, stride=5):\n",
        "    \"\"\" Generate occlusion sensitivity map by blocking parts of the image \"\"\"\n",
        "    heatmap = np.zeros_like(img_array[0, :, :, 0])\n",
        "    original_pred = model.predict(img_array)[0, 0]  # Get original prediction\n",
        "\n",
        "    for i in range(0, img_array.shape[1] - patch_size, stride):\n",
        "        for j in range(0, img_array.shape[2] - patch_size, stride):\n",
        "            occluded_img = img_array.copy()\n",
        "            occluded_img[:, i:i+patch_size, j:j+patch_size, :] = 0  # Block part of image\n",
        "\n",
        "            new_pred = model.predict(occluded_img)[0, 0]  # Get new prediction\n",
        "            heatmap[i:i+patch_size, j:j+patch_size] = original_pred - new_pred  # Difference in prediction\n",
        "\n",
        "    return heatmap\n",
        "\n",
        "# Generate occlusion maps for both images\n",
        "healthy_occlusion = occlusion_sensitivity_map(model, healthy_img_array)\n",
        "infected_occlusion = occlusion_sensitivity_map(model, infected_img_array)\n",
        "\n",
        "# Plot occlusion maps\n",
        "fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
        "axes[0].imshow(healthy_occlusion, cmap=\"hot\")\n",
        "axes[0].set_title(\"Occlusion Map - Healthy Leaf\")\n",
        "axes[0].axis(\"off\")\n",
        "\n",
        "axes[1].imshow(infected_occlusion, cmap=\"hot\")\n",
        "axes[1].set_title(\"Occlusion Map - Infected Leaf\")\n",
        "axes[1].axis(\"off\")\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Confidence Analysis "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Step 1.1: Check Confidence Scores for a Few Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "# Select random test images\n",
        "pointers = [10, 30, 50, 70]  # Change indices to check different images\n",
        "label_map = {0: \"Healthy\", 1: \"Infected\"}  # Adjust according to your dataset\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "\n",
        "for i, pointer in enumerate(pointers):\n",
        "    plt.subplot(2, 2, i+1)\n",
        "\n",
        "    # Load and preprocess the image\n",
        "    label = labels[1]  # 'Infected' category (change to labels[0] for 'Healthy')\n",
        "    img_path = test_path + \"/\" + label + \"/\" + os.listdir(test_path + \"/\" + label)[pointer]\n",
        "    pil_img = image.load_img(img_path, target_size=image_shape)\n",
        "    img_array = image.img_to_array(pil_img) / 255.0\n",
        "    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
        "\n",
        "    # Make prediction\n",
        "    pred_proba = model.predict(img_array)[0, 0]\n",
        "    pred_label = label_map[pred_proba > 0.5]\n",
        "\n",
        "    # Display image with prediction confidence\n",
        "    plt.imshow(pil_img)\n",
        "    plt.title(f\"Pred: {pred_label} ({pred_proba:.2f})\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Step 2: Comparative Model Testing "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Step 2.1: Define a Lighter Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "\n",
        "def create_lighter_model():\n",
        "    \"\"\"Create a smaller CNN model for comparison.\"\"\"\n",
        "\n",
        "    model = Sequential([\n",
        "        Conv2D(32, (3, 3), activation='relu', input_shape=image_shape),\n",
        "        MaxPooling2D((2, 2)),\n",
        "\n",
        "        Conv2D(64, (3, 3), activation='relu'),\n",
        "        MaxPooling2D((2, 2)),\n",
        "\n",
        "        Flatten(),\n",
        "        Dense(64, activation='relu'),\n",
        "        Dropout(0.3),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "    model.compile(loss='binary_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "# Create and display summary of the model\n",
        "lighter_model = create_lighter_model()\n",
        "lighter_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Step 2.2: Train and Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train the model\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "lighter_model.fit(train_set,\n",
        "                  epochs=20,\n",
        "                  validation_data=validation_set,\n",
        "                  callbacks=[early_stop],\n",
        "                  verbose=1)\n",
        "\n",
        "# Evaluate the performance\n",
        "lighter_model.evaluate(test_set)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "lighter_model_history = lighter_model.fit(\n",
        "    train_set,\n",
        "    validation_data=validation_set,\n",
        "    epochs=10,  # Adjust as needed\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Convert history to DataFrame\n",
        "lighter_history = pd.DataFrame(lighter_model_history.history)\n",
        "lighter_history.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "print(lighter_model_history.history.keys())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "print(lighter_model.history.history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create a figure for loss and accuracy\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "# Plot loss\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(lighter_history['loss'], label=\"Training Loss\", linestyle='-')\n",
        "plt.plot(lighter_history['val_loss'], label=\"Validation Loss\", linestyle='--')\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Loss Curve\")\n",
        "plt.legend()\n",
        "\n",
        "# Plot accuracy\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(lighter_history['accuracy'], label=\"Training Accuracy\", linestyle='-')\n",
        "plt.plot(lighter_history['val_accuracy'], label=\"Validation Accuracy\", linestyle='--')\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"Accuracy Curve\")\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Compare Predictions for Multiple Images (CI)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define a list of pointers to check multiple images\n",
        "pointers = [10, 30, 50, 70]  # Compare multiple images\n",
        "label = labels[1]  # 'Infected' (or 'Healthy')\n",
        "\n",
        "fig, axes = plt.subplots(1, len(pointers), figsize=(15, 5))\n",
        "\n",
        "for i, pointer in enumerate(pointers):\n",
        "    img_list = os.listdir(test_path + '/' + label)\n",
        "    if pointer >= len(img_list):\n",
        "        print(f\"Skipping pointer {pointer}, index out of range.\")\n",
        "        continue\n",
        "\n",
        "    img_path = test_path + '/' + label + '/' + img_list[pointer]\n",
        "\n",
        "    # Load and preprocess the image\n",
        "    img = image.load_img(img_path, target_size=(128, 128))\n",
        "    img_array = image.img_to_array(img) / 255.0\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "    # Make a prediction\n",
        "    pred = model.predict(img_array)[0, 0]\n",
        "    pred_class = \"Healthy\" if pred < 0.5 else \"Infected\"\n",
        "\n",
        "    # Plot the image and prediction result\n",
        "    axes[i].imshow(img)\n",
        "    axes[i].set_title(f\"{pred_class}\\nProb: {pred:.4f}\")\n",
        "    axes[i].axis(\"off\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Load and Predict on a Random Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np\n",
        "import random\n",
        "import os\n",
        "\n",
        "# Select a random image from the test dataset\n",
        "label = random.choice(labels)  # Choose between 'Healthy' and 'Infected'\n",
        "img_list = os.listdir(f\"{test_path}/{label}\")\n",
        "img_name = random.choice(img_list)  # Choose a random image\n",
        "\n",
        "# Load the selected image\n",
        "img_path = f\"{test_path}/{label}/{img_name}\"\n",
        "img = image.load_img(img_path, target_size=image_shape[:2])\n",
        "img_array = image.img_to_array(img) / 255.0  # Normalize pixel values\n",
        "img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
        "\n",
        "# Make prediction\n",
        "pred_proba = model.predict(img_array)[0, 0]  # Extract probability\n",
        "pred_class = \"Healthy\" if pred_proba < 0.5 else \"Infected\"\n",
        "\n",
        "# Display results\n",
        "print(f\"True Label: {label}\")\n",
        "print(f\"Predicted Label: {pred_class}\")\n",
        "print(f\"Prediction Probability: {pred_proba:.4f}\")\n",
        "\n",
        "# Show the image\n",
        "plt.imshow(img)\n",
        "plt.title(f\"True: {label} | Predicted: {pred_class}\\nConfidence: {pred_proba:.2f}\")\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Visualization of Prediction Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "pointers = [10, 30, 50, 70]  # Compare multiple images\n",
        "fig, axes = plt.subplots(1, len(pointers), figsize=(15, 5))\n",
        "\n",
        "for i, pointer in enumerate(pointers):\n",
        "    img_list = os.listdir(f\"{test_path}/{label}\")\n",
        "    if pointer >= len(img_list):\n",
        "        print(f\"Skipping pointer {pointer}, index out of range.\")\n",
        "        continue\n",
        "\n",
        "    img_path = f\"{test_path}/{label}/{img_list[pointer]}\"\n",
        "\n",
        "    # Load and preprocess the image\n",
        "    img = image.load_img(img_path, target_size=image_shape[:2])\n",
        "    img_array = image.img_to_array(img) / 255.0\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "    # Make a prediction\n",
        "    pred = model.predict(img_array)[0, 0]\n",
        "    pred_class = \"Healthy\" if pred < 0.5 else \"Infected\"\n",
        "\n",
        "    # Plot the image and prediction result\n",
        "    axes[i].imshow(img)\n",
        "    axes[i].set_title(f\"{pred_class}\\nProb: {pred:.4f}\")\n",
        "    axes[i].axis(\"off\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conclusion and Next Steps\n",
        "\n",
        "### Summary of Findings\n",
        "- A CNN model and Random Forest classifier were trained to classify cherry leaves as Healthy or Infected with powdery mildew.\n",
        "- The CNN model was trained using image augmentation and early stopping to prevent overfitting.\n",
        "- The Random Forest model was optimized using GridSearchCV, selecting the best hyperparameters for classification.\n",
        "Evaluation results showed:\n",
        "  - CNN Model: [Include final test accuracy]\n",
        "  - Random Forest Model: [Include precision/recall scores]\n",
        "\n",
        "### Model Comparison\n",
        "Model\tAccuracy\tPrecision\tRecall\tF1 Score\n",
        "CNN (Keras)\t[XX%]\t[XX%]\t[XX%]\t[XX%]\n",
        "Random Forest\t[XX%]\t[XX%]\t[XX%]\t[XX%]\n",
        "\n",
        "- CNN performed better on test data, while Random Forest achieved high recall scores.\n",
        "- Final choice of model depends on the business requirement (e.g., if false negatives are more critical, prioritize recall).\n",
        "\n",
        "### Next Steps\n",
        "\n",
        "1. Deploy the selected model:\n",
        "- Convert the model into a Streamlit web application.\n",
        "- Deploy the best model in Heroku.\n",
        "\n",
        "2. Fine-tuning and Improvements:\n",
        "- Try Transfer Learning using pre-trained CNN models (e.g., ResNet, VGG16) for improved feature extraction.\n",
        "- Experiment with different hyperparameters for the CNN model.\n",
        "- Increase the dataset by collecting more images or using synthetic augmentation.\n",
        "\n",
        "3. Monitor and Validate in Production:\n",
        "- Implement real-time evaluation by collecting new image data from the field.\n",
        "- Set up model drift detection to ensure accuracy remains high.\n",
        "\n",
        "4. Future Considerations:\n",
        "- Extend the model to detect other plant diseases.\n",
        "- Build a mobile application for farmers to upload images and receive instant classification results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "interpreter": {
      "hash": "8b8334dab9339717f727a1deaf837b322d7a41c20d15cc86be99a8e69ceec8ce"
    },
    "kernelspec": {
      "display_name": "Python 3.8.12 64-bit ('3.8.12': pyenv)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
